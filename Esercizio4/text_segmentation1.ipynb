{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 4\n",
    "\n",
    "Si richiede un'implementazione di un sistema di text segmentation, prendendo ispirazione da TextTiling. In particolare, partendo da un corpus composto da almeno 3 sezioni su tematiche molto diverse (ad es. potete usare paragrafi da tre pagine di Wikipedia diverse), dovrete testare il vostro sistema in modo che riesca ad individuare le giuste linee di taglio (o quasi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clear_sentence(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation] #tolgo la punteggiatura\n",
    "    tokens = [token.lower() for token in tokens] # sostituisco le maiuscole con le minuscole\n",
    "    tokens = [token for token in tokens if token not in stop_words] # rimuovo le stop words\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens] # lemmatizzo\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcolo per ogni frase il numero di parole\n",
    "\n",
    "def calcola_occorrenze_parole_frasi(sentences):\n",
    "    words_per_sentence = {}\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        tokens = clear_sentence(sentence)\n",
    "        words_per_sentence[i] = {}\n",
    "        for token in tokens:\n",
    "            if token not in words_per_sentence[i]:\n",
    "                words_per_sentence[i][token] = 1\n",
    "            else:\n",
    "                words_per_sentence[i][token] += 1\n",
    "    \n",
    "    return words_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividi words_per_sentence in k parti uguali\n",
    "def divide_in_k_parts(words_per_sentence, k=3):\n",
    "    parts = {}\n",
    "    num_sentences = len(words_per_sentence)\n",
    "    sentence_per_part = num_sentences // k\n",
    "    break_points = [sentence_per_part*i for i in range(1,k)]\n",
    "    break_points = list(np.insert(break_points, 0, 0))\n",
    "\n",
    "    j = 0\n",
    "    num_parte = 0\n",
    "    parts[num_parte] = {}\n",
    "\n",
    "    for i, sentence in enumerate(words_per_sentence):\n",
    "        if j < sentence_per_part or num_parte == k-1:\n",
    "            parts[num_parte][i] = words_per_sentence[sentence]\n",
    "            j += 1\n",
    "        else:\n",
    "            j = 0\n",
    "            num_parte += 1\n",
    "            if num_parte not in parts:\n",
    "                parts[num_parte] = {}\n",
    "            parts[num_parte][i] = words_per_sentence[sentence]\n",
    "            j += 1\n",
    "    \n",
    "    return parts, break_points\n",
    "\n",
    "def divide_in_parts(words_per_sentence, break_points=[0,4,10]):\n",
    "    parts = {}\n",
    "    num_sentences = len(words_per_sentence)\n",
    "    num_parte = 1\n",
    "    parts[0] = {}\n",
    "\n",
    "    j = 0\n",
    "    for i, sentence in enumerate(words_per_sentence):\n",
    "        if num_parte > len(break_points)-1:\n",
    "            parts[num_parte-1][i] = words_per_sentence[sentence]\n",
    "            j += 1\n",
    "        else:\n",
    "            if j < break_points[num_parte]:\n",
    "                parts[num_parte-1][i] = words_per_sentence[sentence]\n",
    "                j += 1\n",
    "            else:\n",
    "                num_parte += 1\n",
    "                if num_parte-1 not in parts:\n",
    "                    parts[num_parte-1] = {}\n",
    "                parts[num_parte-1][i] = words_per_sentence[sentence]\n",
    "                j += 1\n",
    "\n",
    "    return parts\n",
    "\n",
    "sentences = pd.read_csv('corpus.csv')['sentence']\n",
    "\n",
    "words_per_sentence = calcola_occorrenze_parole_frasi(sentences)\n",
    "parts, break_points = divide_in_k_parts(words_per_sentence, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per ogni parte calcolo l'overlap lessicale nelle frasi a due a due\n",
    "def compute_cohesion(parts):\n",
    "    print('\\n')\n",
    "    print('COMPUTE COHESION')\n",
    "    words_count = []\n",
    "    j = 0\n",
    "\n",
    "    for index, part in enumerate(parts):\n",
    "        words_count_per_block = {}\n",
    "        i = list(parts[index].keys())[0]\n",
    "\n",
    "        for sentence in parts[index]:\n",
    "            if i+1 in parts[index]:\n",
    "                words_count_per_block[j] = 0\n",
    "\n",
    "                for word in parts[index][i]:\n",
    "                    if word in parts[index][i+1]:\n",
    "                        words_count_per_block[j] += parts[index][i][word] + parts[index][i+1][word]\n",
    "\n",
    "                j += 1\n",
    "                i += 1\n",
    "        words_count.append(words_count_per_block)\n",
    "\n",
    "    print(words_count)\n",
    "\n",
    "    #plot words_count\n",
    "    #for index, words_count_per_block in enumerate(words_count):\n",
    "    #    plt.plot(words_count_per_block.keys(), words_count_per_block.values(), label=f'parte {index+1}')\n",
    "\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    return words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_break_points(parts, words_count):\n",
    "    new_parts = parts.copy()\n",
    "\n",
    "    for i, counts in enumerate(words_count):\n",
    "        min_value = min(counts.values())\n",
    "        min_value_position = [k for k, v in counts.items() if v == min_value][0]\n",
    "\n",
    "        keys_to_update = []\n",
    "\n",
    "        for j, part in enumerate(parts[i]):\n",
    "            if j > min_value_position:\n",
    "                keys_to_update.append(j)\n",
    "\n",
    "        for key in keys_to_update:\n",
    "            new_parts[i+1][key] = new_parts[i][key]\n",
    "            del new_parts[i][key]\n",
    "    \n",
    "    return new_parts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_word_count(words_count):\n",
    "    for count in words_count:\n",
    "        print(sum(count.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_break_points(words_count, break_points):\n",
    "    #print('\\n')\n",
    "    print('RECALCULATE BREAK POINTS')\n",
    "    print('words count', words_count)\n",
    "    print('initial break points', break_points)\n",
    "\n",
    "    start_sentences = {k: words_count[k] for k in list(words_count)[:break_points[1]]}\n",
    "    medium_sentences = {k: words_count[k] for k in list(words_count)[break_points[1]:break_points[2]]}\n",
    "    end_sentences = {k: words_count[k] for k in list(words_count)[break_points[2]:]}\n",
    "\n",
    "    start_min_value_positions = [k for k, v in start_sentences.items() if v == min(start_sentences.values())]\n",
    "    medium_min_value_positions = [k for k, v in medium_sentences.items() if v == min(medium_sentences.values())]\n",
    "    end_min_value_positions = [k for k, v in end_sentences.items() if v == min(end_sentences.values())]\n",
    "\n",
    "    #1\n",
    "    start_pos = start_min_value_positions[len(start_min_value_positions)-1]\n",
    "    if (medium_min_value_positions[0] != break_points[1]):\n",
    "        medium_pos = medium_min_value_positions[0]\n",
    "    else:\n",
    "        if len(medium_min_value_positions) > 1:\n",
    "            medium_pos = medium_min_value_positions[1]\n",
    "        else:\n",
    "            #trova il secondo minimo\n",
    "            medium_pos = [k for k, v in medium_sentences.items() if v == sorted(medium_sentences.values())[1]][0]\n",
    "\n",
    "\n",
    "    if (break_points[1] - start_pos) > (medium_pos - break_points[1]):\n",
    "        break_points[1] = medium_pos\n",
    "    else:\n",
    "        break_points[1] = start_pos\n",
    "\n",
    "    print('#1 -',start_pos, medium_pos)\n",
    "\n",
    "    #2\n",
    "    medium_pos = medium_min_value_positions[len(medium_min_value_positions)-1]\n",
    "    if (end_min_value_positions[0] != break_points[1]):\n",
    "        end_pos = end_min_value_positions[0]\n",
    "    else:\n",
    "        if len(end_min_value_positions) > 1:\n",
    "            end_pos = end_min_value_positions[1]\n",
    "        else:\n",
    "            #trova il secondo minimo\n",
    "            end_pos = [k for k, v in end_sentences.items() if v == sorted(end_sentences.values())[1]][0]\n",
    "\n",
    "\n",
    "    if (break_points[2] - medium_pos) > (end_pos - break_points[2]):\n",
    "        break_points[2] = end_pos\n",
    "    else:\n",
    "        break_points[2] = medium_pos\n",
    "\n",
    "    print('#2 -',start_pos, medium_pos)\n",
    "    print('final break points', break_points)\n",
    "\n",
    "    print(start_min_value_positions, medium_min_value_positions, end_min_value_positions)\n",
    "    #print('\\n')\n",
    "\n",
    "    return break_points\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break_points [0, 7, 14]\n",
      "parts {0: {0: {'juventus': 2, 'founded': 1, 'sport-club': 1, 'late': 1, '1897': 1, 'pupil': 1, 'massimo': 1, \"d'azeglio\": 1, 'lyceum': 1, 'school': 1, 'turin': 1, 'among': 1, 'eugenio': 1, 'canfari': 2, 'enrico': 1}, 1: {'renamed': 1, 'foot-ball': 1, 'club': 1, 'juventus': 1, 'two': 1, 'year': 1, 'later': 1}, 2: {'club': 1, 'joined': 1, '1900': 1, 'italian': 1, 'football': 1, 'championship': 1}, 3: {'juventus': 1, 'played': 1, 'first': 1, 'italian': 1, 'football': 1, 'championship': 1, 'match': 1, '11': 1, 'march': 1, '1900': 1, '1–0': 1, 'defeat': 1, 'torinese': 1}, 4: {'1904': 1, 'businessman': 1, 'marco': 1, 'ajmone-marsan': 1, 'revived': 1, 'finance': 1, 'juventus': 1, 'making': 1, 'possible': 1, 'transfer': 1, 'training': 1, 'field': 1, 'piazza': 1, \"d'armi\": 1, 'appropriate': 1, 'velodrome': 1, 'umberto': 1}, 5: {'period': 1, 'team': 1, 'wore': 1, 'pink': 1, 'black': 1, 'kit': 1}, 6: {'juventus': 1, 'first': 1, '1905': 1, 'italian': 1, 'football': 1, 'championship': 1, 'playing': 1, 'velodrome': 1, 'umberto': 1, 'ground': 1}}, 1: {7: {'time': 1, 'club': 1, 'colour': 1, 'changed': 1, 'black': 1, 'white': 1, 'stripe': 1, 'inspired': 1, 'english': 1, 'side': 1, 'notts': 1, 'county': 1}, 8: {'split': 1, 'club': 1, '1906': 1, 'staff': 1, 'considered': 1, 'moving': 1, 'juve': 1, 'turin': 1}, 9: {'alfred': 1, 'dick': 1, 'club': 1, \"'s\": 1, 'president': 1, 'unhappy': 1, 'left': 1, 'prominent': 1, 'player': 1, 'found': 1, 'fbc': 1, 'torino': 1, 'turn': 1, 'spawned': 1, 'derby': 1, 'della': 1, 'mole': 1, 'juventus': 1, 'spent': 1, 'much': 1, 'period': 1, 'steadily': 1, 'rebuilding': 1, 'split': 1, 'surviving': 1, 'first': 1, 'world': 1, 'war': 1}, 10: {'natural': 2, 'language': 3, 'processing': 1, 'nlp': 1, 'interdisciplinary': 1, 'subfield': 1, 'linguistics': 1, 'computer': 3, 'science': 1, 'artificial': 1, 'intelligence': 1, 'concerned': 1, 'interaction': 1, 'human': 1, 'particular': 1, 'program': 1, 'process': 1, 'analyze': 1, 'large': 1, 'amount': 1, 'data': 1}, 11: {'goal': 1, 'computer': 1, 'capable': 1, 'understanding': 1, 'content': 1, 'document': 1, 'including': 1, 'contextual': 1, 'nuance': 1, 'language': 1, 'within': 1}, 12: {'technology': 1, 'accurately': 1, 'extract': 1, 'information': 1, 'insight': 1, 'contained': 1, 'document': 2, 'well': 1, 'categorize': 1, 'organize': 1}, 13: {'challenge': 1, 'natural': 1, 'language': 1, 'processing': 1, 'frequently': 1, 'involve': 1, 'speech': 1, 'recognition': 1, 'natural-language': 2, 'understanding': 1, 'generation': 1}}, 2: {14: {'kurt': 1, 'donald': 1, 'cobain': 1, 'american': 1, 'musician': 1, 'co-founder': 1, 'lead': 1, 'vocalist': 1, 'guitarist': 1, 'primary': 1, 'songwriter': 1, 'rock': 1, 'band': 1, 'nirvana': 1}, 15: {'angst-fueled': 1, 'songwriting': 1, 'anti-establishment': 1, 'persona': 1, 'cobain': 1, \"'s\": 1, 'composition': 1, 'widened': 1, 'thematic': 1, 'convention': 1, 'mainstream': 1, 'rock': 1}, 16: {'heralded': 1, 'spokesman': 1, 'generation': 1, 'x': 1, 'highly': 1, 'recognized': 1, 'one': 1, 'influential': 1, 'alternative': 1, 'rock': 1, 'musician': 1}, 17: {'cobain': 1, 'formed': 1, 'nirvana': 1, 'krist': 1, 'novoselic': 1, 'aaron': 1, 'burckhard': 1, '1987': 1, 'established': 1, 'part': 1, 'seattle': 1, 'music': 1, 'scene': 1, 'later': 1, 'became': 1, 'known': 1, 'grunge': 1}, 18: {'signing': 1, 'dgc': 1, 'record': 1, 'nirvana': 1, 'found': 1, 'commercial': 1, 'success': 1, 'single': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'critically': 1, 'acclaimed': 1, 'second': 1, 'album': 1, 'nevermind': 1, '1991': 1}, 19: {'although': 1, 'cobain': 1, 'hailed': 1, 'voice': 1, 'generation': 1, 'following': 1, 'nirvana': 1, \"'s\": 1, 'sudden': 1, 'success': 1, 'resented': 1, 'believing': 1, 'message': 1, 'artistic': 1, 'vision': 1, 'misinterpreted': 1, 'public': 1}, 20: {'addition': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'cobain': 1, 'wrote': 1, 'many': 1, 'hit': 1, 'song': 1, 'nirvana': 1, 'including': 1, 'come': 1, 'lithium': 1, 'bloom': 1, 'something': 1, 'way': 1, 'heart-shaped': 1, 'box': 1, 'apology': 1, 'girl': 1, 'aneurysm': 1, 'know': 1, \"'re\": 1, 'right': 1}}}\n",
      "\n",
      "\n",
      "COMPUTE COHESION\n",
      "[{0: 3, 1: 2, 2: 8, 3: 2, 4: 0, 5: 0}, {6: 2, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0}, {12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}]\n",
      "15\n",
      "17\n",
      "16\n",
      "RECALCULATE BREAK POINTS\n",
      "words count {0: 3, 1: 2, 2: 8, 3: 2, 4: 0, 5: 0, 6: 2, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0, 12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}\n",
      "initial break points [0, 7, 14]\n",
      "#1 - 5 8\n",
      "#2 - 5 11\n",
      "final break points [0, 8, 14]\n",
      "[4, 5] [8, 11] [14]\n",
      "break_points [0, 8, 14]\n",
      "parts {0: {0: {'juventus': 2, 'founded': 1, 'sport-club': 1, 'late': 1, '1897': 1, 'pupil': 1, 'massimo': 1, \"d'azeglio\": 1, 'lyceum': 1, 'school': 1, 'turin': 1, 'among': 1, 'eugenio': 1, 'canfari': 2, 'enrico': 1}, 1: {'renamed': 1, 'foot-ball': 1, 'club': 1, 'juventus': 1, 'two': 1, 'year': 1, 'later': 1}, 2: {'club': 1, 'joined': 1, '1900': 1, 'italian': 1, 'football': 1, 'championship': 1}, 3: {'juventus': 1, 'played': 1, 'first': 1, 'italian': 1, 'football': 1, 'championship': 1, 'match': 1, '11': 1, 'march': 1, '1900': 1, '1–0': 1, 'defeat': 1, 'torinese': 1}, 4: {'1904': 1, 'businessman': 1, 'marco': 1, 'ajmone-marsan': 1, 'revived': 1, 'finance': 1, 'juventus': 1, 'making': 1, 'possible': 1, 'transfer': 1, 'training': 1, 'field': 1, 'piazza': 1, \"d'armi\": 1, 'appropriate': 1, 'velodrome': 1, 'umberto': 1}, 5: {'period': 1, 'team': 1, 'wore': 1, 'pink': 1, 'black': 1, 'kit': 1}, 6: {'juventus': 1, 'first': 1, '1905': 1, 'italian': 1, 'football': 1, 'championship': 1, 'playing': 1, 'velodrome': 1, 'umberto': 1, 'ground': 1}, 7: {'time': 1, 'club': 1, 'colour': 1, 'changed': 1, 'black': 1, 'white': 1, 'stripe': 1, 'inspired': 1, 'english': 1, 'side': 1, 'notts': 1, 'county': 1}}, 1: {8: {'split': 1, 'club': 1, '1906': 1, 'staff': 1, 'considered': 1, 'moving': 1, 'juve': 1, 'turin': 1}, 9: {'alfred': 1, 'dick': 1, 'club': 1, \"'s\": 1, 'president': 1, 'unhappy': 1, 'left': 1, 'prominent': 1, 'player': 1, 'found': 1, 'fbc': 1, 'torino': 1, 'turn': 1, 'spawned': 1, 'derby': 1, 'della': 1, 'mole': 1, 'juventus': 1, 'spent': 1, 'much': 1, 'period': 1, 'steadily': 1, 'rebuilding': 1, 'split': 1, 'surviving': 1, 'first': 1, 'world': 1, 'war': 1}, 10: {'natural': 2, 'language': 3, 'processing': 1, 'nlp': 1, 'interdisciplinary': 1, 'subfield': 1, 'linguistics': 1, 'computer': 3, 'science': 1, 'artificial': 1, 'intelligence': 1, 'concerned': 1, 'interaction': 1, 'human': 1, 'particular': 1, 'program': 1, 'process': 1, 'analyze': 1, 'large': 1, 'amount': 1, 'data': 1}, 11: {'goal': 1, 'computer': 1, 'capable': 1, 'understanding': 1, 'content': 1, 'document': 1, 'including': 1, 'contextual': 1, 'nuance': 1, 'language': 1, 'within': 1}, 12: {'technology': 1, 'accurately': 1, 'extract': 1, 'information': 1, 'insight': 1, 'contained': 1, 'document': 2, 'well': 1, 'categorize': 1, 'organize': 1}, 13: {'challenge': 1, 'natural': 1, 'language': 1, 'processing': 1, 'frequently': 1, 'involve': 1, 'speech': 1, 'recognition': 1, 'natural-language': 2, 'understanding': 1, 'generation': 1}}, 2: {14: {'kurt': 1, 'donald': 1, 'cobain': 1, 'american': 1, 'musician': 1, 'co-founder': 1, 'lead': 1, 'vocalist': 1, 'guitarist': 1, 'primary': 1, 'songwriter': 1, 'rock': 1, 'band': 1, 'nirvana': 1}, 15: {'angst-fueled': 1, 'songwriting': 1, 'anti-establishment': 1, 'persona': 1, 'cobain': 1, \"'s\": 1, 'composition': 1, 'widened': 1, 'thematic': 1, 'convention': 1, 'mainstream': 1, 'rock': 1}, 16: {'heralded': 1, 'spokesman': 1, 'generation': 1, 'x': 1, 'highly': 1, 'recognized': 1, 'one': 1, 'influential': 1, 'alternative': 1, 'rock': 1, 'musician': 1}, 17: {'cobain': 1, 'formed': 1, 'nirvana': 1, 'krist': 1, 'novoselic': 1, 'aaron': 1, 'burckhard': 1, '1987': 1, 'established': 1, 'part': 1, 'seattle': 1, 'music': 1, 'scene': 1, 'later': 1, 'became': 1, 'known': 1, 'grunge': 1}, 18: {'signing': 1, 'dgc': 1, 'record': 1, 'nirvana': 1, 'found': 1, 'commercial': 1, 'success': 1, 'single': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'critically': 1, 'acclaimed': 1, 'second': 1, 'album': 1, 'nevermind': 1, '1991': 1}, 19: {'although': 1, 'cobain': 1, 'hailed': 1, 'voice': 1, 'generation': 1, 'following': 1, 'nirvana': 1, \"'s\": 1, 'sudden': 1, 'success': 1, 'resented': 1, 'believing': 1, 'message': 1, 'artistic': 1, 'vision': 1, 'misinterpreted': 1, 'public': 1}, 20: {'addition': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'cobain': 1, 'wrote': 1, 'many': 1, 'hit': 1, 'song': 1, 'nirvana': 1, 'including': 1, 'come': 1, 'lithium': 1, 'bloom': 1, 'something': 1, 'way': 1, 'heart-shaped': 1, 'box': 1, 'apology': 1, 'girl': 1, 'aneurysm': 1, 'know': 1, \"'re\": 1, 'right': 1}}}\n",
      "\n",
      "\n",
      "COMPUTE COHESION\n",
      "[{0: 3, 1: 2, 2: 8, 3: 2, 4: 0, 5: 0, 6: 0}, {7: 4, 8: 0, 9: 8, 10: 3, 11: 0}, {12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}]\n",
      "15\n",
      "15\n",
      "16\n",
      "RECALCULATE BREAK POINTS\n",
      "words count {0: 3, 1: 2, 2: 8, 3: 2, 4: 0, 5: 0, 6: 0, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0, 12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}\n",
      "initial break points [0, 8, 14]\n",
      "#1 - 6 11\n",
      "#2 - 6 11\n",
      "final break points [0, 6, 14]\n",
      "[4, 5, 6] [8, 11] [14]\n",
      "break_points [0, 6, 14]\n",
      "parts {0: {0: {'juventus': 2, 'founded': 1, 'sport-club': 1, 'late': 1, '1897': 1, 'pupil': 1, 'massimo': 1, \"d'azeglio\": 1, 'lyceum': 1, 'school': 1, 'turin': 1, 'among': 1, 'eugenio': 1, 'canfari': 2, 'enrico': 1}, 1: {'renamed': 1, 'foot-ball': 1, 'club': 1, 'juventus': 1, 'two': 1, 'year': 1, 'later': 1}, 2: {'club': 1, 'joined': 1, '1900': 1, 'italian': 1, 'football': 1, 'championship': 1}, 3: {'juventus': 1, 'played': 1, 'first': 1, 'italian': 1, 'football': 1, 'championship': 1, 'match': 1, '11': 1, 'march': 1, '1900': 1, '1–0': 1, 'defeat': 1, 'torinese': 1}, 4: {'1904': 1, 'businessman': 1, 'marco': 1, 'ajmone-marsan': 1, 'revived': 1, 'finance': 1, 'juventus': 1, 'making': 1, 'possible': 1, 'transfer': 1, 'training': 1, 'field': 1, 'piazza': 1, \"d'armi\": 1, 'appropriate': 1, 'velodrome': 1, 'umberto': 1}, 5: {'period': 1, 'team': 1, 'wore': 1, 'pink': 1, 'black': 1, 'kit': 1}}, 1: {6: {'juventus': 1, 'first': 1, '1905': 1, 'italian': 1, 'football': 1, 'championship': 1, 'playing': 1, 'velodrome': 1, 'umberto': 1, 'ground': 1}, 7: {'time': 1, 'club': 1, 'colour': 1, 'changed': 1, 'black': 1, 'white': 1, 'stripe': 1, 'inspired': 1, 'english': 1, 'side': 1, 'notts': 1, 'county': 1}, 8: {'split': 1, 'club': 1, '1906': 1, 'staff': 1, 'considered': 1, 'moving': 1, 'juve': 1, 'turin': 1}, 9: {'alfred': 1, 'dick': 1, 'club': 1, \"'s\": 1, 'president': 1, 'unhappy': 1, 'left': 1, 'prominent': 1, 'player': 1, 'found': 1, 'fbc': 1, 'torino': 1, 'turn': 1, 'spawned': 1, 'derby': 1, 'della': 1, 'mole': 1, 'juventus': 1, 'spent': 1, 'much': 1, 'period': 1, 'steadily': 1, 'rebuilding': 1, 'split': 1, 'surviving': 1, 'first': 1, 'world': 1, 'war': 1}, 10: {'natural': 2, 'language': 3, 'processing': 1, 'nlp': 1, 'interdisciplinary': 1, 'subfield': 1, 'linguistics': 1, 'computer': 3, 'science': 1, 'artificial': 1, 'intelligence': 1, 'concerned': 1, 'interaction': 1, 'human': 1, 'particular': 1, 'program': 1, 'process': 1, 'analyze': 1, 'large': 1, 'amount': 1, 'data': 1}, 11: {'goal': 1, 'computer': 1, 'capable': 1, 'understanding': 1, 'content': 1, 'document': 1, 'including': 1, 'contextual': 1, 'nuance': 1, 'language': 1, 'within': 1}, 12: {'technology': 1, 'accurately': 1, 'extract': 1, 'information': 1, 'insight': 1, 'contained': 1, 'document': 2, 'well': 1, 'categorize': 1, 'organize': 1}, 13: {'challenge': 1, 'natural': 1, 'language': 1, 'processing': 1, 'frequently': 1, 'involve': 1, 'speech': 1, 'recognition': 1, 'natural-language': 2, 'understanding': 1, 'generation': 1}}, 2: {14: {'kurt': 1, 'donald': 1, 'cobain': 1, 'american': 1, 'musician': 1, 'co-founder': 1, 'lead': 1, 'vocalist': 1, 'guitarist': 1, 'primary': 1, 'songwriter': 1, 'rock': 1, 'band': 1, 'nirvana': 1}, 15: {'angst-fueled': 1, 'songwriting': 1, 'anti-establishment': 1, 'persona': 1, 'cobain': 1, \"'s\": 1, 'composition': 1, 'widened': 1, 'thematic': 1, 'convention': 1, 'mainstream': 1, 'rock': 1}, 16: {'heralded': 1, 'spokesman': 1, 'generation': 1, 'x': 1, 'highly': 1, 'recognized': 1, 'one': 1, 'influential': 1, 'alternative': 1, 'rock': 1, 'musician': 1}, 17: {'cobain': 1, 'formed': 1, 'nirvana': 1, 'krist': 1, 'novoselic': 1, 'aaron': 1, 'burckhard': 1, '1987': 1, 'established': 1, 'part': 1, 'seattle': 1, 'music': 1, 'scene': 1, 'later': 1, 'became': 1, 'known': 1, 'grunge': 1}, 18: {'signing': 1, 'dgc': 1, 'record': 1, 'nirvana': 1, 'found': 1, 'commercial': 1, 'success': 1, 'single': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'critically': 1, 'acclaimed': 1, 'second': 1, 'album': 1, 'nevermind': 1, '1991': 1}, 19: {'although': 1, 'cobain': 1, 'hailed': 1, 'voice': 1, 'generation': 1, 'following': 1, 'nirvana': 1, \"'s\": 1, 'sudden': 1, 'success': 1, 'resented': 1, 'believing': 1, 'message': 1, 'artistic': 1, 'vision': 1, 'misinterpreted': 1, 'public': 1}, 20: {'addition': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'cobain': 1, 'wrote': 1, 'many': 1, 'hit': 1, 'song': 1, 'nirvana': 1, 'including': 1, 'come': 1, 'lithium': 1, 'bloom': 1, 'something': 1, 'way': 1, 'heart-shaped': 1, 'box': 1, 'apology': 1, 'girl': 1, 'aneurysm': 1, 'know': 1, \"'re\": 1, 'right': 1}}}\n",
      "\n",
      "\n",
      "COMPUTE COHESION\n",
      "[{0: 3, 1: 2, 2: 8, 3: 2, 4: 0}, {5: 0, 6: 2, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0}, {12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}]\n",
      "15\n",
      "17\n",
      "16\n",
      "RECALCULATE BREAK POINTS\n",
      "words count {0: 3, 1: 2, 2: 8, 3: 2, 4: 0, 5: 0, 6: 2, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0, 12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}\n",
      "initial break points [0, 6, 14]\n",
      "#1 - 5 8\n",
      "#2 - 5 11\n",
      "final break points [0, 5, 14]\n",
      "[4, 5] [8, 11] [14]\n",
      "break_points [0, 5, 14]\n",
      "parts {0: {0: {'juventus': 2, 'founded': 1, 'sport-club': 1, 'late': 1, '1897': 1, 'pupil': 1, 'massimo': 1, \"d'azeglio\": 1, 'lyceum': 1, 'school': 1, 'turin': 1, 'among': 1, 'eugenio': 1, 'canfari': 2, 'enrico': 1}, 1: {'renamed': 1, 'foot-ball': 1, 'club': 1, 'juventus': 1, 'two': 1, 'year': 1, 'later': 1}, 2: {'club': 1, 'joined': 1, '1900': 1, 'italian': 1, 'football': 1, 'championship': 1}, 3: {'juventus': 1, 'played': 1, 'first': 1, 'italian': 1, 'football': 1, 'championship': 1, 'match': 1, '11': 1, 'march': 1, '1900': 1, '1–0': 1, 'defeat': 1, 'torinese': 1}, 4: {'1904': 1, 'businessman': 1, 'marco': 1, 'ajmone-marsan': 1, 'revived': 1, 'finance': 1, 'juventus': 1, 'making': 1, 'possible': 1, 'transfer': 1, 'training': 1, 'field': 1, 'piazza': 1, \"d'armi\": 1, 'appropriate': 1, 'velodrome': 1, 'umberto': 1}}, 1: {5: {'period': 1, 'team': 1, 'wore': 1, 'pink': 1, 'black': 1, 'kit': 1}, 6: {'juventus': 1, 'first': 1, '1905': 1, 'italian': 1, 'football': 1, 'championship': 1, 'playing': 1, 'velodrome': 1, 'umberto': 1, 'ground': 1}, 7: {'time': 1, 'club': 1, 'colour': 1, 'changed': 1, 'black': 1, 'white': 1, 'stripe': 1, 'inspired': 1, 'english': 1, 'side': 1, 'notts': 1, 'county': 1}, 8: {'split': 1, 'club': 1, '1906': 1, 'staff': 1, 'considered': 1, 'moving': 1, 'juve': 1, 'turin': 1}, 9: {'alfred': 1, 'dick': 1, 'club': 1, \"'s\": 1, 'president': 1, 'unhappy': 1, 'left': 1, 'prominent': 1, 'player': 1, 'found': 1, 'fbc': 1, 'torino': 1, 'turn': 1, 'spawned': 1, 'derby': 1, 'della': 1, 'mole': 1, 'juventus': 1, 'spent': 1, 'much': 1, 'period': 1, 'steadily': 1, 'rebuilding': 1, 'split': 1, 'surviving': 1, 'first': 1, 'world': 1, 'war': 1}, 10: {'natural': 2, 'language': 3, 'processing': 1, 'nlp': 1, 'interdisciplinary': 1, 'subfield': 1, 'linguistics': 1, 'computer': 3, 'science': 1, 'artificial': 1, 'intelligence': 1, 'concerned': 1, 'interaction': 1, 'human': 1, 'particular': 1, 'program': 1, 'process': 1, 'analyze': 1, 'large': 1, 'amount': 1, 'data': 1}, 11: {'goal': 1, 'computer': 1, 'capable': 1, 'understanding': 1, 'content': 1, 'document': 1, 'including': 1, 'contextual': 1, 'nuance': 1, 'language': 1, 'within': 1}, 12: {'technology': 1, 'accurately': 1, 'extract': 1, 'information': 1, 'insight': 1, 'contained': 1, 'document': 2, 'well': 1, 'categorize': 1, 'organize': 1}, 13: {'challenge': 1, 'natural': 1, 'language': 1, 'processing': 1, 'frequently': 1, 'involve': 1, 'speech': 1, 'recognition': 1, 'natural-language': 2, 'understanding': 1, 'generation': 1}}, 2: {14: {'kurt': 1, 'donald': 1, 'cobain': 1, 'american': 1, 'musician': 1, 'co-founder': 1, 'lead': 1, 'vocalist': 1, 'guitarist': 1, 'primary': 1, 'songwriter': 1, 'rock': 1, 'band': 1, 'nirvana': 1}, 15: {'angst-fueled': 1, 'songwriting': 1, 'anti-establishment': 1, 'persona': 1, 'cobain': 1, \"'s\": 1, 'composition': 1, 'widened': 1, 'thematic': 1, 'convention': 1, 'mainstream': 1, 'rock': 1}, 16: {'heralded': 1, 'spokesman': 1, 'generation': 1, 'x': 1, 'highly': 1, 'recognized': 1, 'one': 1, 'influential': 1, 'alternative': 1, 'rock': 1, 'musician': 1}, 17: {'cobain': 1, 'formed': 1, 'nirvana': 1, 'krist': 1, 'novoselic': 1, 'aaron': 1, 'burckhard': 1, '1987': 1, 'established': 1, 'part': 1, 'seattle': 1, 'music': 1, 'scene': 1, 'later': 1, 'became': 1, 'known': 1, 'grunge': 1}, 18: {'signing': 1, 'dgc': 1, 'record': 1, 'nirvana': 1, 'found': 1, 'commercial': 1, 'success': 1, 'single': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'critically': 1, 'acclaimed': 1, 'second': 1, 'album': 1, 'nevermind': 1, '1991': 1}, 19: {'although': 1, 'cobain': 1, 'hailed': 1, 'voice': 1, 'generation': 1, 'following': 1, 'nirvana': 1, \"'s\": 1, 'sudden': 1, 'success': 1, 'resented': 1, 'believing': 1, 'message': 1, 'artistic': 1, 'vision': 1, 'misinterpreted': 1, 'public': 1}, 20: {'addition': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'cobain': 1, 'wrote': 1, 'many': 1, 'hit': 1, 'song': 1, 'nirvana': 1, 'including': 1, 'come': 1, 'lithium': 1, 'bloom': 1, 'something': 1, 'way': 1, 'heart-shaped': 1, 'box': 1, 'apology': 1, 'girl': 1, 'aneurysm': 1, 'know': 1, \"'re\": 1, 'right': 1}}}\n",
      "\n",
      "\n",
      "COMPUTE COHESION\n",
      "[{0: 3, 1: 2, 2: 8, 3: 2}, {4: 0, 5: 0, 6: 2, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0}, {12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}]\n",
      "15\n",
      "17\n",
      "16\n",
      "RECALCULATE BREAK POINTS\n",
      "words count {0: 3, 1: 2, 2: 8, 3: 2, 4: 0, 5: 0, 6: 2, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0, 12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}\n",
      "initial break points [0, 5, 14]\n",
      "#1 - 4 8\n",
      "#2 - 4 11\n",
      "final break points [0, 4, 14]\n",
      "[4] [5, 8, 11] [14]\n",
      "break_points [0, 4, 14]\n",
      "parts {0: {0: {'juventus': 2, 'founded': 1, 'sport-club': 1, 'late': 1, '1897': 1, 'pupil': 1, 'massimo': 1, \"d'azeglio\": 1, 'lyceum': 1, 'school': 1, 'turin': 1, 'among': 1, 'eugenio': 1, 'canfari': 2, 'enrico': 1}, 1: {'renamed': 1, 'foot-ball': 1, 'club': 1, 'juventus': 1, 'two': 1, 'year': 1, 'later': 1}, 2: {'club': 1, 'joined': 1, '1900': 1, 'italian': 1, 'football': 1, 'championship': 1}, 3: {'juventus': 1, 'played': 1, 'first': 1, 'italian': 1, 'football': 1, 'championship': 1, 'match': 1, '11': 1, 'march': 1, '1900': 1, '1–0': 1, 'defeat': 1, 'torinese': 1}}, 1: {4: {'1904': 1, 'businessman': 1, 'marco': 1, 'ajmone-marsan': 1, 'revived': 1, 'finance': 1, 'juventus': 1, 'making': 1, 'possible': 1, 'transfer': 1, 'training': 1, 'field': 1, 'piazza': 1, \"d'armi\": 1, 'appropriate': 1, 'velodrome': 1, 'umberto': 1}, 5: {'period': 1, 'team': 1, 'wore': 1, 'pink': 1, 'black': 1, 'kit': 1}, 6: {'juventus': 1, 'first': 1, '1905': 1, 'italian': 1, 'football': 1, 'championship': 1, 'playing': 1, 'velodrome': 1, 'umberto': 1, 'ground': 1}, 7: {'time': 1, 'club': 1, 'colour': 1, 'changed': 1, 'black': 1, 'white': 1, 'stripe': 1, 'inspired': 1, 'english': 1, 'side': 1, 'notts': 1, 'county': 1}, 8: {'split': 1, 'club': 1, '1906': 1, 'staff': 1, 'considered': 1, 'moving': 1, 'juve': 1, 'turin': 1}, 9: {'alfred': 1, 'dick': 1, 'club': 1, \"'s\": 1, 'president': 1, 'unhappy': 1, 'left': 1, 'prominent': 1, 'player': 1, 'found': 1, 'fbc': 1, 'torino': 1, 'turn': 1, 'spawned': 1, 'derby': 1, 'della': 1, 'mole': 1, 'juventus': 1, 'spent': 1, 'much': 1, 'period': 1, 'steadily': 1, 'rebuilding': 1, 'split': 1, 'surviving': 1, 'first': 1, 'world': 1, 'war': 1}, 10: {'natural': 2, 'language': 3, 'processing': 1, 'nlp': 1, 'interdisciplinary': 1, 'subfield': 1, 'linguistics': 1, 'computer': 3, 'science': 1, 'artificial': 1, 'intelligence': 1, 'concerned': 1, 'interaction': 1, 'human': 1, 'particular': 1, 'program': 1, 'process': 1, 'analyze': 1, 'large': 1, 'amount': 1, 'data': 1}, 11: {'goal': 1, 'computer': 1, 'capable': 1, 'understanding': 1, 'content': 1, 'document': 1, 'including': 1, 'contextual': 1, 'nuance': 1, 'language': 1, 'within': 1}, 12: {'technology': 1, 'accurately': 1, 'extract': 1, 'information': 1, 'insight': 1, 'contained': 1, 'document': 2, 'well': 1, 'categorize': 1, 'organize': 1}, 13: {'challenge': 1, 'natural': 1, 'language': 1, 'processing': 1, 'frequently': 1, 'involve': 1, 'speech': 1, 'recognition': 1, 'natural-language': 2, 'understanding': 1, 'generation': 1}}, 2: {14: {'kurt': 1, 'donald': 1, 'cobain': 1, 'american': 1, 'musician': 1, 'co-founder': 1, 'lead': 1, 'vocalist': 1, 'guitarist': 1, 'primary': 1, 'songwriter': 1, 'rock': 1, 'band': 1, 'nirvana': 1}, 15: {'angst-fueled': 1, 'songwriting': 1, 'anti-establishment': 1, 'persona': 1, 'cobain': 1, \"'s\": 1, 'composition': 1, 'widened': 1, 'thematic': 1, 'convention': 1, 'mainstream': 1, 'rock': 1}, 16: {'heralded': 1, 'spokesman': 1, 'generation': 1, 'x': 1, 'highly': 1, 'recognized': 1, 'one': 1, 'influential': 1, 'alternative': 1, 'rock': 1, 'musician': 1}, 17: {'cobain': 1, 'formed': 1, 'nirvana': 1, 'krist': 1, 'novoselic': 1, 'aaron': 1, 'burckhard': 1, '1987': 1, 'established': 1, 'part': 1, 'seattle': 1, 'music': 1, 'scene': 1, 'later': 1, 'became': 1, 'known': 1, 'grunge': 1}, 18: {'signing': 1, 'dgc': 1, 'record': 1, 'nirvana': 1, 'found': 1, 'commercial': 1, 'success': 1, 'single': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'critically': 1, 'acclaimed': 1, 'second': 1, 'album': 1, 'nevermind': 1, '1991': 1}, 19: {'although': 1, 'cobain': 1, 'hailed': 1, 'voice': 1, 'generation': 1, 'following': 1, 'nirvana': 1, \"'s\": 1, 'sudden': 1, 'success': 1, 'resented': 1, 'believing': 1, 'message': 1, 'artistic': 1, 'vision': 1, 'misinterpreted': 1, 'public': 1}, 20: {'addition': 1, 'smell': 1, 'like': 1, 'teen': 1, 'spirit': 1, 'cobain': 1, 'wrote': 1, 'many': 1, 'hit': 1, 'song': 1, 'nirvana': 1, 'including': 1, 'come': 1, 'lithium': 1, 'bloom': 1, 'something': 1, 'way': 1, 'heart-shaped': 1, 'box': 1, 'apology': 1, 'girl': 1, 'aneurysm': 1, 'know': 1, \"'re\": 1, 'right': 1}}}\n",
      "\n",
      "\n",
      "COMPUTE COHESION\n",
      "[{0: 3, 1: 2, 2: 8}, {3: 0, 4: 0, 5: 0, 6: 2, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0}, {12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}]\n",
      "13\n",
      "17\n",
      "16\n",
      "RECALCULATE BREAK POINTS\n",
      "words count {0: 3, 1: 2, 2: 8, 3: 0, 4: 0, 5: 0, 6: 2, 7: 4, 8: 0, 9: 8, 10: 3, 11: 0, 12: 4, 13: 2, 14: 0, 15: 2, 16: 4, 17: 4}\n",
      "initial break points [0, 4, 14]\n",
      "#1 - 3 5\n",
      "#2 - 3 11\n",
      "final break points [0, 3, 14]\n",
      "[3] [4, 5, 8, 11] [14]\n",
      "break_points [0, 3, 14]\n"
     ]
    }
   ],
   "source": [
    "sentences = pd.read_csv('corpus.csv')['sentence']\n",
    "\n",
    "words_per_sentence = calcola_occorrenze_parole_frasi(sentences)\n",
    "parts, break_points = divide_in_k_parts(words_per_sentence, k=3)\n",
    "print('break_points', break_points)\n",
    "\n",
    "for i in range(5):\n",
    "    print('parts', parts)\n",
    "    cohoesion_parts = compute_cohesion(parts)\n",
    "    sum_word_count(cohoesion_parts)\n",
    "\n",
    "    merged_cohoesion_parts = {}\n",
    "    for cohoesion_part in cohoesion_parts:\n",
    "        merged_cohoesion_parts.update(cohoesion_part)\n",
    "\n",
    "    #ricalcolo i break points\n",
    "    break_points = recalculate_break_points(merged_cohoesion_parts, break_points)\n",
    "    #ricalcolo le parti in base ai nuovi break points\n",
    "    parts = divide_in_parts(words_per_sentence, break_points)\n",
    "    print('break_points', break_points)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
