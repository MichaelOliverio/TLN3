{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3\n",
    "\n",
    "Si richiede un’implementazione della teoria sulle valenze di Patrick Hanks. In particolare, partendo da un corpus a scelta e uno specifico verbo (tendenzialmente non troppo frequente e/o generico ma nemmeno raro), l’idea è di costruire dei possibili cluster semantici, con relativa frequenza. Ad es. dato il verbo \"to see\" con valenza = 2, e usando un parser sintattico (ad es. Spacy), si possono collezionare eventuali fillers per i ruoli di subj e obj del verbo, per poi convertirli in semantic types. Un cluster frequente su \"to see\" potrebbe unire subj = noun.person con obj = noun.artifact. Si richiede di partire da un corpus di almeno alcune centinaia di istanze del verbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodi di supporto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizzazione della frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def normalize(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation] #tolgo la punteggiatura\n",
    "    tokens = [token.lower() for token in tokens] # sostituisco le maiuscole con le minuscole\n",
    "    tokens = [token for token in tokens if token not in stop_words] # rimuovo le stop words\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens] # lemmatizzo\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Simplified Lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplified_lesk(word, context):\n",
    "    best_sense = None\n",
    "    max_overlap = 0\n",
    "\n",
    "    for sense in wn.synsets(word):\n",
    "        signature = set(normalize(sense.definition())).union(set(normalize(' '.join(sense.examples()))))\n",
    "        overlap = len(context.intersection(signature))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "    \n",
    "    return best_sense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generazione di tutte le strutture verbali per ogni verbo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metodo generale che per ogni verbo tira fuori la collezione, quindi tutte le sue\n",
    "valenze, andando anche a creare stesse valenze ma con pos diversi\n",
    "'''\n",
    "def generate_trees(corpus):\n",
    "    parser = spacy.load('en_core_web_sm')\n",
    "    verbs = {}\n",
    "\n",
    "    i = 0\n",
    "    for sentence in corpus['sentence']:\n",
    "        sentence = sentence.replace('<s>', '').replace('</s>', '').replace('\"', '').replace(\"'\", '')[1:]\n",
    "        parsified_sentence = parser(sentence)\n",
    "        #spacy.displacy.render(parsified_sentence, style=\"dep\", options={\"compact\": True}) # visualizza il grafo\n",
    "\n",
    "\n",
    "        verb_deps = {}\n",
    "\n",
    "        # per ogni verbo della frase prendo tutte le dipendenze di quel verbo\n",
    "        for token in parsified_sentence:\n",
    "            if token.head.pos_ == 'VERB':\n",
    "                if token.head.lemma_ not in verb_deps:\n",
    "                    verb_deps[token.head.lemma_] = set()\n",
    "\n",
    "                if token.dep_ != 'ROOT' and token.dep_ != 'punct':\n",
    "                    verb_deps[token.head.lemma_].add(token.dep_)\n",
    "\n",
    "        # maniglia al verbo \n",
    "        current_keys = {}\n",
    "\n",
    "        # controllo se esiste già un verbo con le stesse dipendenze altrimenti lo creo\n",
    "        for verb, deps in verb_deps.items():\n",
    "            current_keys[verb] = None\n",
    "\n",
    "            # prelevo le chiavi che matchano con il verbo corrente (es. \"see_1\" matcha con \"see\")\n",
    "            matching_keys = [key for key in verbs.keys() if verb in key]\n",
    "\n",
    "\n",
    "            # controllo se esiste già un verbo con le stesse dipendenze\n",
    "            if matching_keys:\n",
    "                for key in matching_keys:\n",
    "                    if deps == set(verbs[key].keys()):\n",
    "                        current_keys[verb] = key\n",
    "\n",
    "            # se non esiste un verbo con le stesse dipendenze lo creo\n",
    "            if current_keys[verb] is None:\n",
    "                current_keys[verb] = verb + \"_\" + str(i)\n",
    "                verbs[current_keys[verb]] = {}\n",
    "                for dep in deps:\n",
    "                    verbs[current_keys[verb]][dep] = set()\n",
    "                i += 1\n",
    "\n",
    "        # A questo punto aggiungo le nuove informazioni agli slot del verbo\n",
    "        for token in parsified_sentence:\n",
    "            if token.dep_ != 'ROOT' and token.dep_ != 'punct':\n",
    "                lemma_key = current_keys.get(token.head.lemma_)\n",
    "                if lemma_key is not None:\n",
    "                    verb_slot = verbs[lemma_key].get(token.dep_)\n",
    "                    if verb_slot is not None:\n",
    "                        synset = simplified_lesk(token.text, set(normalize(sentence)))\n",
    "                        verb_slot.add((token.text, synset))\n",
    "    return verbs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generazione delle strutture verbali con valenza 2 e slot subj e dobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metodo che per ogni verbo considera solo la valenza 2 andando a fare filling degli slot nsubj e dobj\n",
    "'''\n",
    "def generate_trees_val_2(corpus):\n",
    "    parser = spacy.load('en_core_web_sm')\n",
    "    verbs = {}\n",
    "\n",
    "    i = 0\n",
    "    for sentence in corpus['sentence']:\n",
    "        sentence = sentence.replace('<s>', '').replace('</s>', '').replace('\"', '').replace(\"'\", '')[1:]\n",
    "        parsified_sentence = parser(sentence)\n",
    "        #spacy.displacy.render(parsified_sentence, style=\"dep\", options={\"compact\": True}) # visualizza il grafo\n",
    "\n",
    "\n",
    "        # A questo punto aggiungo le nuove informazioni agli slot del verbo\n",
    "        for token in parsified_sentence:\n",
    "            if token.head.pos_ == 'VERB':\n",
    "                if token.head.lemma_ not in verbs:\n",
    "                    verbs[token.head.lemma_] = {\n",
    "                        'nsubj': set(),\n",
    "                        'dobj': set()\n",
    "                    }\n",
    "\n",
    "                if token.dep_ == 'nsubj' or token.dep_ == 'dobj':\n",
    "                    synset = simplified_lesk(token.text, set(normalize(sentence)))\n",
    "                    verbs[token.head.lemma_][token.dep_].add((token.text, synset))\n",
    "\n",
    "    return verbs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rimozione dei verbi con slot vuoti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rimuovo dalla lista dei verbi quelli che non hanno istanze di nsubj o dobj\n",
    "'''\n",
    "def remove_verbs_with_no_nsubj_or_dobj(verbs):\n",
    "    verbs_to_remove = []\n",
    "    for verb, slots in verbs.items():\n",
    "        if not slots['nsubj'] or not slots['dobj']:\n",
    "            verbs_to_remove.append(verb)\n",
    "\n",
    "    for verb in verbs_to_remove:\n",
    "        verbs.pop(verb)\n",
    "\n",
    "    return verbs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribuzione dei semantic types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aggiunge i semantic types agli slot dei verbi\n",
    "'''\n",
    "def add_semantic_types(verbs):\n",
    "    sm_slots = {}\n",
    "\n",
    "    for verb, slots in verbs.items():\n",
    "        sm_slots[verb] = {}\n",
    "        \n",
    "        for slot, values in slots.items():\n",
    "            semantic_types = []\n",
    "\n",
    "            for _, synset in values:\n",
    "                if synset is not None:\n",
    "                    semantic_types.append(synset.lexname().split('.')[1]) # ottengo il semantic type  del synset\n",
    "\n",
    "            if semantic_types:\n",
    "                semantic_type = max(set(semantic_types), key = semantic_types.count) # majority voting\n",
    "                sm_slots[verb].update({slot: [semantic_type]})\n",
    "\n",
    "    # screma i verbi che non hanno semantic type\n",
    "    verbs_to_remove = []\n",
    "    for verb, slots in sm_slots.items():\n",
    "        if not slots:\n",
    "            verbs_to_remove.append(verb)\n",
    "\n",
    "    for verb in verbs_to_remove:\n",
    "        sm_slots.pop(verb)\n",
    "                \n",
    "    return sm_slots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stampa della collezione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "per ogni verbo in verbs stampa un albero con i soggetti e gli oggetti\n",
    "'''\n",
    "def print_trees(verbs):\n",
    "    for verb in verbs:\n",
    "        print(verb)\n",
    "        for dep in verbs[verb]:\n",
    "            print('\\t', dep)\n",
    "            for word in verbs[verb][dep]:\n",
    "                print('\\t\\t', word)\n",
    "                \n",
    "        print('-----------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('english_wikipedia_sentence.csv')\n",
    "verbs = generate_trees_val_2(corpus)\n",
    "verbs = remove_verbs_with_no_nsubj_or_dobj(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "\t nsubj\n",
      "\t\t ('plants', Synset('plant.n.01'))\n",
      "\t\t ('Chaucer', None)\n",
      "\t\t ('some', Synset('some.s.02'))\n",
      "\t dobj\n",
      "\t\t ('trend', Synset('tendency.n.04'))\n",
      "-----------------------------\n",
      "use\n",
      "\t nsubj\n",
      "\t\t ('who', None)\n",
      "\t\t ('translations', Synset('transformation.n.05'))\n",
      "\t\t ('that', None)\n",
      "\t dobj\n",
      "\t\t ('pitch', Synset('pitch.n.03'))\n",
      "\t\t ('yupana', None)\n",
      "\t\t ('equations', None)\n",
      "\t\t ('hypothesis', Synset('hypothesis.n.02'))\n",
      "\t\t ('pesticides', None)\n",
      "\t\t ('term', Synset('term.n.02'))\n",
      "-----------------------------\n",
      "see\n",
      "\t nsubj\n",
      "\t\t ('year', Synset('year.n.01'))\n",
      "\t\t ('crew', Synset('crew.v.01'))\n",
      "\t\t ('Secretary', None)\n",
      "\t\t ('Jung', None)\n",
      "\t\t ('portions', Synset('part.n.01'))\n",
      "\t\t ('goats', Synset('goat.n.01'))\n",
      "\t\t ('Swift', Synset('fleet.s.01'))\n",
      "\t\t ('Greeks', None)\n",
      "\t\t ('I', Synset('one.n.01'))\n",
      "\t\t ('Boys', Synset('male_child.n.01'))\n",
      "\t\t ('1993', None)\n",
      "\t\t ('he', Synset('helium.n.01'))\n",
      "\t\t ('Gershwin', Synset('gershwin.n.01'))\n",
      "\t\t ('we', None)\n",
      "\t\t ('studies', Synset('study.n.05'))\n",
      "\t\t ('distortions', Synset('distorted_shape.n.01'))\n",
      "\t\t ('wave', Synset('wave.n.02'))\n",
      "\t\t ('period', Synset('period.n.04'))\n",
      "\t\t ('some', None)\n",
      "\t\t ('Crescent', Synset('crescent.n.01'))\n",
      "\t\t ('Borman', None)\n",
      "\t\t ('century', None)\n",
      "\t\t ('that', None)\n",
      "\t\t ('she', None)\n",
      "\t\t ('Odysseus', Synset('odysseus.n.01'))\n",
      "\t\t ('abacus', None)\n",
      "\t\t ('it', None)\n",
      "\t\t ('quarter', Synset('quarter.n.04'))\n",
      "\t\t ('he', None)\n",
      "\t\t ('historians', None)\n",
      "\t\t ('rate', Synset('rate.n.01'))\n",
      "\t\t ('table', Synset('table.n.01'))\n",
      "\t\t ('I', Synset('iodine.n.01'))\n",
      "\t\t ('they', None)\n",
      "\t\t ('BC', Synset('bc.r.01'))\n",
      "\t\t ('philosophy', Synset('philosophy.n.03'))\n",
      "\t\t ('which', None)\n",
      "\t\t ('who', None)\n",
      "\t\t ('Rand', Synset('rand.n.02'))\n",
      "\t\t ('Lincoln', None)\n",
      "\t\t ('workers', Synset('worker.n.01'))\n",
      "\t\t ('Ages', Synset('age.n.01'))\n",
      "\t\t ('Lord', Synset('lord.v.01'))\n",
      "\t\t ('one', Synset('one.n.01'))\n",
      "\t\t ('crops', Synset('crop.n.03'))\n",
      "\t\t ('animators', Synset('animator.n.02'))\n",
      "\t\t ('Italy', None)\n",
      "\t dobj\n",
      "\t\t ('image', Synset('image.n.01'))\n",
      "\t\t ('-', None)\n",
      "\t\t ('participation', None)\n",
      "\t\t ('Anarchism', None)\n",
      "\t\t ('History', Synset('history.n.01'))\n",
      "\t\t ('formation', Synset('formation.n.01'))\n",
      "\t\t ('number', Synset('number.n.01'))\n",
      "\t\t ('what', None)\n",
      "\t\t ('domestication', Synset('domestication.n.03'))\n",
      "\t\t ('them', None)\n",
      "\t\t ('apple', None)\n",
      "\t\t ('drop', Synset('drop.n.03'))\n",
      "\t\t ('struggle', Synset('struggle.n.01'))\n",
      "\t\t ('acids', Synset('acid.n.01'))\n",
      "\t\t ('activation', None)\n",
      "\t\t ('disappointments', Synset('disappointment.n.01'))\n",
      "\t\t ('subsidies', Synset('subsidy.n.01'))\n",
      "\t\t ('feet', Synset('foot.n.02'))\n",
      "\t\t ('Earth', Synset('earth.n.01'))\n",
      "\t\t ('List', Synset('tilt.n.04'))\n",
      "\t\t ('decrease', Synset('decrease.n.01'))\n",
      "\t\t ('Moon', Synset('moon.n.01'))\n",
      "\t\t ('summation', Synset('summation.n.04'))\n",
      "\t\t ('predicables', None)\n",
      "\t\t ('Theologica', None)\n",
      "\t\t ('projection', Synset('projection.n.02'))\n",
      "\t\t ('similarities', None)\n",
      "\t\t ('success', Synset('success.n.01'))\n",
      "\t\t ('hypothesis', Synset('hypothesis.n.02'))\n",
      "\t\t ('stages', Synset('phase.n.01'))\n",
      "\t\t ('destruction', Synset('destruction.n.01'))\n",
      "\t\t ('government', Synset('government.n.01'))\n",
      "\t\t ('appearance', Synset('appearance.n.05'))\n",
      "\t\t ('Gen', Synset('gen.n.01'))\n",
      "\t\t ('assassinations', None)\n",
      "\t\t ('slavery', None)\n",
      "\t\t ('naturism', None)\n",
      "\t\t ('struggles', Synset('struggle.n.01'))\n",
      "\t\t ('graph', Synset('graph.v.01'))\n",
      "\t\t ('Boulanger', None)\n",
      "\t\t ('mountains', None)\n",
      "\t\t ('use', Synset('practice.v.04'))\n",
      "\t\t ('that', None)\n",
      "\t\t ('underwater', None)\n",
      "\t\t ('it', None)\n",
      "\t\t ('averaging', None)\n",
      "\t\t ('activity', Synset('activity.n.04'))\n",
      "\t\t ('Apollo', None)\n",
      "\t\t ('figure', Synset('figure.n.01'))\n",
      "\t\t ('alchemy', Synset('chemistry.n.03'))\n",
      "\t\t ('table', Synset('table.n.01'))\n",
      "\t\t ('side', Synset('side.n.01'))\n",
      "\t\t ('state', Synset('state.n.02'))\n",
      "\t\t ('which', None)\n",
      "\t\t ('improvements', Synset('improvement.n.02'))\n",
      "\t\t ('award', Synset('award.n.01'))\n",
      "\t\t ('Universals', Synset('universal.n.03'))\n",
      "\t\t ('use', Synset('use.n.01'))\n",
      "\t\t ('anarchism', None)\n",
      "\t\t ('sum', Synset('sum.n.01'))\n",
      "\t\t ('oil', Synset('oil.n.02'))\n",
      "\t\t ('Charales', Synset('charales.n.01'))\n",
      "\t\t ('children', Synset('child.n.01'))\n",
      "\t\t ('non', None)\n",
      "\t\t ('violence', Synset('violence.n.01'))\n",
      "\t\t ('events', Synset('event.n.02'))\n",
      "\t\t ('heat', Synset('hotness.n.01'))\n",
      "\t\t ('Classification', None)\n",
      "\t\t ('wheels', Synset('wheel.n.03'))\n",
      "\t\t ('elements', Synset('element.n.04'))\n",
      "\t\t ('tragedies', None)\n",
      "\t\t ('upheaval', Synset('turbulence.n.03'))\n",
      "\t\t ('crime', Synset('crime.n.01'))\n",
      "\t\t ('face', Synset('face.n.01'))\n",
      "-----------------------------\n",
      "ravage\n",
      "\t nsubj\n",
      "\t\t ('West', Synset('west.n.03'))\n",
      "\t dobj\n",
      "\t\t ('rest', Synset('lie.v.06'))\n",
      "-----------------------------\n",
      "attract\n",
      "\t nsubj\n",
      "\t\t ('anarchism', None)\n",
      "\t dobj\n",
      "\t\t ('following', Synset('follow.v.08'))\n",
      "-----------------------------\n",
      "reject\n",
      "\t nsubj\n",
      "\t\t ('that', None)\n",
      "\t\t ('anarchism', None)\n",
      "\t dobj\n",
      "\t\t ('violence', Synset('violence.n.01'))\n",
      "\t\t ('property', Synset('property.n.01'))\n",
      "-----------------------------\n",
      "distinguish\n",
      "\t nsubj\n",
      "\t\t ('deficits', Synset('deficit.n.01'))\n",
      "\t dobj\n",
      "\t\t ('autism', Synset('autism.n.01'))\n",
      "-----------------------------\n",
      "underlie\n",
      "\t nsubj\n",
      "\t\t ('picture', Synset('picture.n.01'))\n",
      "\t\t ('ability', None)\n",
      "\t dobj\n",
      "\t\t ('disturbance', Synset('perturbation.n.03'))\n",
      "-----------------------------\n",
      "have\n",
      "\t nsubj\n",
      "\t\t ('surface', Synset('surface.n.01'))\n",
      "\t\t ('Algeria', Synset('algeria.n.01'))\n",
      "\t\t ('animal', Synset('animal.s.01'))\n",
      "\t\t ('alkanes', None)\n",
      "\t\t ('Alchemy', Synset('chemistry.n.03'))\n",
      "\t\t ('areas', Synset('area.n.06'))\n",
      "\t\t ('they', None)\n",
      "\t\t ('electrons', None)\n",
      "\t\t ('Agassi', None)\n",
      "\t dobj\n",
      "\t\t ('relationship', Synset('relationship.n.01'))\n",
      "\t\t ('values', Synset('values.n.01'))\n",
      "\t\t ('energy', Synset('department_of_energy.n.01'))\n",
      "\t\t ('populations', Synset('population.n.01'))\n",
      "\t\t ('vision', Synset('vision.n.03'))\n",
      "\t\t ('sight', Synset('sight.n.02'))\n",
      "\t\t ('talent', Synset('endowment.n.01'))\n",
      "\t\t ('albedo', None)\n",
      "\t\t ('tusks', Synset('horn.v.01'))\n",
      "\t\t ('some', Synset('some.s.02'))\n",
      "-----------------------------\n",
      "do\n",
      "\t nsubj\n",
      "\t\t ('he', None)\n",
      "\t\t ('forests', Synset('forest.n.01'))\n",
      "\t dobj\n",
      "\t\t ('it', None)\n",
      "\t\t ('something', None)\n",
      "-----------------------------\n",
      "bring\n",
      "\t nsubj\n",
      "\t\t ('who', None)\n",
      "\t\t ('development', Synset('growth.n.01'))\n",
      "\t dobj\n",
      "\t\t ('thought', Synset('idea.n.01'))\n",
      "\t\t ('level', Synset('degree.n.01'))\n",
      "\t\t ('plague', Synset('infestation.n.02'))\n",
      "\t\t ('host', Synset('master_of_ceremonies.n.01'))\n",
      "-----------------------------\n",
      "hold\n",
      "\t nsubj\n",
      "\t\t ('she', None)\n",
      "\t dobj\n",
      "\t\t ('him', None)\n",
      "-----------------------------\n",
      "take\n",
      "\t nsubj\n",
      "\t\t ('Achilles', Synset('achilles.n.01'))\n",
      "\t dobj\n",
      "\t\t ('photo', None)\n",
      "\t\t ('spear', Synset('spear.v.01'))\n",
      "-----------------------------\n",
      "grab\n",
      "\t nsubj\n",
      "\t\t ('Lincoln', None)\n",
      "\t dobj\n",
      "\t\t ('assailant', None)\n",
      "-----------------------------\n",
      "show\n",
      "\t nsubj\n",
      "\t\t ('Ununennium', None)\n",
      "\t dobj\n",
      "\t\t ('moon', Synset('moonlight.n.01'))\n",
      "\t\t ('state', Synset('state.n.02'))\n",
      "-----------------------------\n",
      "contrast\n",
      "\t nsubj\n",
      "\t\t ('Foner', None)\n",
      "\t dobj\n",
      "\t\t ('abolitionists', Synset('abolitionist.n.01'))\n",
      "-----------------------------\n",
      "hurt\n",
      "\t nsubj\n",
      "\t\t ('it', None)\n",
      "\t dobj\n",
      "\t\t ('people', Synset('people.n.01'))\n",
      "-----------------------------\n",
      "send\n",
      "\t nsubj\n",
      "\t\t ('commander', Synset('commander.n.03'))\n",
      "\t dobj\n",
      "\t\t ('request', Synset('request.n.02'))\n",
      "-----------------------------\n",
      "make\n",
      "\t nsubj\n",
      "\t\t ('factors', Synset('component.n.01'))\n",
      "\t\t ('Division', Synset('division.n.01'))\n",
      "\t\t ('Paterson', None)\n",
      "\t dobj\n",
      "\t\t ('reference', Synset('mention.n.01'))\n",
      "\t\t ('specializations', Synset('specialization.n.02'))\n",
      "\t\t ('comments', Synset('remark.n.01'))\n",
      "-----------------------------\n",
      "constitute\n",
      "\t nsubj\n",
      "\t\t ('whatever', Synset('any.s.01'))\n",
      "\t dobj\n",
      "\t\t ('house', Synset('house.n.12'))\n",
      "-----------------------------\n",
      "define\n",
      "\t nsubj\n",
      "\t\t ('us', None)\n",
      "\t dobj\n",
      "\t\t ('something', None)\n",
      "-----------------------------\n",
      "analyze\n",
      "\t nsubj\n",
      "\t\t ('we', None)\n",
      "\t dobj\n",
      "\t\t ('form', Synset('form.n.01'))\n",
      "-----------------------------\n",
      "stand\n",
      "\t nsubj\n",
      "\t\t ('himself', None)\n",
      "\t dobj\n",
      "\t\t ('test', Synset('test.n.02'))\n",
      "-----------------------------\n",
      "contain\n",
      "\t nsubj\n",
      "\t\t ('which', None)\n",
      "\t dobj\n",
      "\t\t ('neutrons', Synset('neutron.n.01'))\n",
      "\t\t ('error', Synset('mistake.n.01'))\n",
      "-----------------------------\n",
      "stave\n",
      "\t nsubj\n",
      "\t\t ('Nature', Synset('nature.n.02'))\n",
      "\t dobj\n",
      "\t\t ('vanity', Synset('vanity.n.02'))\n",
      "-----------------------------\n",
      "give\n",
      "\t nsubj\n",
      "\t\t ('I', Synset('iodine.n.01'))\n",
      "\t\t ('Apollo', None)\n",
      "\t dobj\n",
      "\t\t ('faculties', None)\n",
      "\t\t ('animal', Synset('animal.s.01'))\n",
      "\t\t ('horns', Synset('horn.n.08'))\n",
      "\t\t ('ability', None)\n",
      "\t\t ('water', Synset('body_of_water.n.01'))\n",
      "-----------------------------\n",
      "blend\n",
      "\t nsubj\n",
      "\t\t ('thinkers', None)\n",
      "\t dobj\n",
      "\t\t ('philosophy', Synset('philosophy.n.02'))\n",
      "-----------------------------\n",
      "contact\n",
      "\t nsubj\n",
      "\t\t ('he', None)\n",
      "\t dobj\n",
      "\t\t ('associates', Synset('associate.n.04'))\n",
      "-----------------------------\n",
      "win\n",
      "\t nsubj\n",
      "\t\t ('Locker', None)\n",
      "\t\t ('which', None)\n",
      "\t\t ('Agassi', None)\n",
      "\t dobj\n",
      "\t\t ('Documentary', Synset('documentary.n.01'))\n",
      "\t\t ('doubles', Synset('double.n.01'))\n",
      "-----------------------------\n",
      "perform\n",
      "\t nsubj\n",
      "\t\t ('people', Synset('people.n.01'))\n",
      "\t dobj\n",
      "\t\t ('acts', Synset('work.v.03'))\n",
      "-----------------------------\n",
      "find\n",
      "\t nsubj\n",
      "\t\t ('they', None)\n",
      "\t dobj\n",
      "\t\t ('what', None)\n",
      "-----------------------------\n",
      "else\n",
      "\t nsubj\n",
      "\t\t ('someone', None)\n",
      "\t dobj\n",
      "\t\t ('gain', Synset('acquire.v.05'))\n",
      "-----------------------------\n",
      "call\n",
      "\t nsubj\n",
      "\t\t ('we', None)\n",
      "\t dobj\n",
      "\t\t ('civilizations', Synset('civilization.n.01'))\n",
      "-----------------------------\n",
      "spur\n",
      "\t nsubj\n",
      "\t\t ('crisis', Synset('crisis.n.01'))\n",
      "\t dobj\n",
      "\t\t ('interest', Synset('interest.n.05'))\n",
      "-----------------------------\n",
      "compare\n",
      "\t nsubj\n",
      "\t\t ('articles', Synset('article.n.02'))\n",
      "\t dobj\n",
      "\t\t ('events', Synset('event.n.02'))\n",
      "-----------------------------\n",
      "include\n",
      "\t nsubj\n",
      "\t\t ('animals', None)\n",
      "\t dobj\n",
      "\t\t ('anatomy', Synset('anatomy.n.01'))\n",
      "\t\t ('study', Synset('study.n.02'))\n",
      "\t\t ('boars', Synset('wild_boar.n.01'))\n",
      "-----------------------------\n",
      "write\n",
      "\t nsubj\n",
      "\t\t ('she', None)\n",
      "\t dobj\n",
      "\t\t ('histories', Synset('history.n.01'))\n",
      "-----------------------------\n",
      "devote\n",
      "\t nsubj\n",
      "\t\t ('Newton', None)\n",
      "\t dobj\n",
      "\t\t ('more', None)\n",
      "-----------------------------\n",
      "believe\n",
      "\t nsubj\n",
      "\t\t ('Johnson', None)\n",
      "\t\t ('one', Synset('one.n.01'))\n",
      "\t dobj\n",
      "\t\t ('her', None)\n",
      "-----------------------------\n",
      "possess\n",
      "\t nsubj\n",
      "\t\t ('nature', Synset('nature.n.01'))\n",
      "\t dobj\n",
      "\t\t ('form', Synset('kind.n.01'))\n",
      "-----------------------------\n",
      "stress\n",
      "\t nsubj\n",
      "\t\t ('each', Synset('each.s.01'))\n",
      "\t dobj\n",
      "\t\t ('nature', Synset('nature.n.02'))\n",
      "-----------------------------\n",
      "compile\n",
      "\t nsubj\n",
      "\t\t ('Agassi', None)\n",
      "\t dobj\n",
      "\t\t ('performances', Synset('performance.n.04'))\n",
      "-----------------------------\n",
      "describe\n",
      "\t nsubj\n",
      "\t\t ('who', None)\n",
      "\t dobj\n",
      "\t\t ('flight', Synset('flight.n.01'))\n",
      "\t\t ('Earth', Synset('earth.n.01'))\n",
      "-----------------------------\n",
      "reach\n",
      "\t nsubj\n",
      "\t\t ('Agassi', None)\n",
      "\t dobj\n",
      "\t\t ('semifinals', Synset('semifinal.n.01'))\n",
      "-----------------------------\n",
      "motivate\n",
      "\t nsubj\n",
      "\t\t ('This', None)\n",
      "\t dobj\n",
      "\t\t ('Orwell', None)\n",
      "-----------------------------\n",
      "allow\n",
      "\t nsubj\n",
      "\t\t ('which', None)\n",
      "\t dobj\n",
      "\t\t ('growth', Synset('growth.n.02'))\n",
      "-----------------------------\n",
      "temper\n",
      "\t nsubj\n",
      "\t\t ('she', None)\n",
      "\t dobj\n",
      "\t\t ('this', None)\n",
      "-----------------------------\n",
      "recall\n",
      "\t nsubj\n",
      "\t\t ('I', None)\n",
      "\t dobj\n",
      "\t\t ('something', None)\n",
      "-----------------------------\n",
      "present\n",
      "\t nsubj\n",
      "\t\t ('memory', Synset('memory.n.01'))\n",
      "\t dobj\n",
      "\t\t ('itself', None)\n",
      "-----------------------------\n",
      "apply\n",
      "\t nsubj\n",
      "\t\t ('model', Synset('model.n.01'))\n",
      "\t\t ('experimenter', Synset('experimenter.n.01'))\n",
      "\t dobj\n",
      "\t\t ('treatments', Synset('treatment.n.01'))\n",
      "-----------------------------\n",
      "delimit\n",
      "\t nsubj\n",
      "\t\t ('which', None)\n",
      "\t dobj\n",
      "\t\t ('orders', Synset('order.n.02'))\n",
      "-----------------------------\n",
      "patent\n",
      "\t nsubj\n",
      "\t\t ('Claridge', None)\n",
      "\t dobj\n",
      "\t\t ('use', Synset('use.n.01'))\n",
      "-----------------------------\n",
      "keep\n",
      "\t nsubj\n",
      "\t\t ('controls', Synset('control.n.01'))\n",
      "\t dobj\n",
      "\t\t ('him', None)\n",
      "-----------------------------\n",
      "plant\n",
      "\t nsubj\n",
      "\t\t ('they', None)\n",
      "\t\t ('missions', Synset('mission.n.02'))\n",
      "\t dobj\n",
      "\t\t ('flags', Synset('flag.n.01'))\n",
      "-----------------------------\n",
      "witness\n",
      "\t nsubj\n",
      "\t\t ('Aldrin', None)\n",
      "\t dobj\n",
      "\t\t ('Earthrise', None)\n",
      "\t\t ('topple', Synset('tumble.v.01'))\n",
      "\t\t ('it', Synset('information_technology.n.01'))\n",
      "-----------------------------\n",
      "study\n",
      "\t nsubj\n",
      "\t\t ('Neil', None)\n",
      "\t dobj\n",
      "\t\t ('indicator', None)\n",
      "-----------------------------\n",
      "image\n",
      "\t nsubj\n",
      "\t\t ('Orbiter', Synset('satellite.n.01'))\n",
      "\t dobj\n",
      "\t\t ('sites', Synset('site.n.01'))\n",
      "-----------------------------\n",
      "spend\n",
      "\t nsubj\n",
      "\t\t ('crew', Synset('crew.v.01'))\n",
      "\t dobj\n",
      "\t\t ('transmission', None)\n",
      "-----------------------------\n",
      "illuminate\n",
      "\t nsubj\n",
      "\t\t ('shafts', Synset('shot.n.09'))\n",
      "\t dobj\n",
      "\t\t ('surface', Synset('surface.n.01'))\n",
      "-----------------------------\n",
      "hit\n",
      "\t nsubj\n",
      "\t\t ('they', None)\n",
      "\t dobj\n",
      "\t\t ('top', Synset('top.n.01'))\n",
      "-----------------------------\n",
      "choose\n",
      "\t nsubj\n",
      "\t\t ('magazine', Synset('magazine.n.01'))\n",
      "\t dobj\n",
      "\t\t ('crew', Synset('crew.n.01'))\n",
      "-----------------------------\n",
      "influence\n",
      "\t nsubj\n",
      "\t\t ('who', None)\n",
      "\t dobj\n",
      "\t\t ('events', Synset('event.n.01'))\n",
      "-----------------------------\n",
      "feature\n",
      "\t nsubj\n",
      "\t\t ('Pravda', None)\n",
      "\t\t ('newspaper', Synset('newspaper.n.01'))\n",
      "\t dobj\n",
      "\t\t ('quote', Synset('quote.v.02'))\n",
      "-----------------------------\n",
      "create\n",
      "\t nsubj\n",
      "\t\t ('use', Synset('use.n.01'))\n",
      "\t\t ('approach', Synset('approach.n.01'))\n",
      "\t dobj\n",
      "\t\t ('points', Synset('detail.n.01'))\n",
      "-----------------------------\n",
      "alienate\n",
      "\t nsubj\n",
      "\t\t ('that', None)\n",
      "\t dobj\n",
      "\t\t ('reader', None)\n",
      "-----------------------------\n",
      "direct\n",
      "\t nsubj\n",
      "\t\t ('Swift', Synset('swift.n.01'))\n",
      "\t dobj\n",
      "\t\t ('us', None)\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_trees(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "\t nsubj\n",
      "\t\t all\n",
      "\t dobj\n",
      "\t\t location\n",
      "-----------------------------\n",
      "use\n",
      "\t nsubj\n",
      "\t\t act\n",
      "\t dobj\n",
      "\t\t location\n",
      "-----------------------------\n",
      "see\n",
      "\t nsubj\n",
      "\t\t person\n",
      "\t dobj\n",
      "\t\t act\n",
      "-----------------------------\n",
      "ravage\n",
      "\t nsubj\n",
      "\t\t location\n",
      "\t dobj\n",
      "\t\t stative\n",
      "-----------------------------\n",
      "attract\n",
      "\t dobj\n",
      "\t\t stative\n",
      "-----------------------------\n",
      "reject\n",
      "\t dobj\n",
      "\t\t act\n",
      "-----------------------------\n",
      "distinguish\n",
      "\t nsubj\n",
      "\t\t attribute\n",
      "\t dobj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "underlie\n",
      "\t nsubj\n",
      "\t\t artifact\n",
      "\t dobj\n",
      "\t\t event\n",
      "-----------------------------\n",
      "have\n",
      "\t nsubj\n",
      "\t\t all\n",
      "\t dobj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "do\n",
      "\t nsubj\n",
      "\t\t group\n",
      "-----------------------------\n",
      "bring\n",
      "\t nsubj\n",
      "\t\t process\n",
      "\t dobj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "take\n",
      "\t nsubj\n",
      "\t\t person\n",
      "\t dobj\n",
      "\t\t contact\n",
      "-----------------------------\n",
      "show\n",
      "\t dobj\n",
      "\t\t Tops\n",
      "-----------------------------\n",
      "contrast\n",
      "\t dobj\n",
      "\t\t person\n",
      "-----------------------------\n",
      "hurt\n",
      "\t dobj\n",
      "\t\t group\n",
      "-----------------------------\n",
      "send\n",
      "\t nsubj\n",
      "\t\t person\n",
      "\t dobj\n",
      "\t\t communication\n",
      "-----------------------------\n",
      "make\n",
      "\t nsubj\n",
      "\t\t cognition\n",
      "\t dobj\n",
      "\t\t communication\n",
      "-----------------------------\n",
      "constitute\n",
      "\t nsubj\n",
      "\t\t all\n",
      "\t dobj\n",
      "\t\t artifact\n",
      "-----------------------------\n",
      "analyze\n",
      "\t dobj\n",
      "\t\t communication\n",
      "-----------------------------\n",
      "stand\n",
      "\t dobj\n",
      "\t\t act\n",
      "-----------------------------\n",
      "contain\n",
      "\t dobj\n",
      "\t\t object\n",
      "-----------------------------\n",
      "stave\n",
      "\t nsubj\n",
      "\t\t person\n",
      "\t dobj\n",
      "\t\t attribute\n",
      "-----------------------------\n",
      "give\n",
      "\t nsubj\n",
      "\t\t substance\n",
      "\t dobj\n",
      "\t\t object\n",
      "-----------------------------\n",
      "blend\n",
      "\t dobj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "contact\n",
      "\t dobj\n",
      "\t\t event\n",
      "-----------------------------\n",
      "win\n",
      "\t dobj\n",
      "\t\t communication\n",
      "-----------------------------\n",
      "perform\n",
      "\t nsubj\n",
      "\t\t group\n",
      "\t dobj\n",
      "\t\t social\n",
      "-----------------------------\n",
      "else\n",
      "\t dobj\n",
      "\t\t possession\n",
      "-----------------------------\n",
      "call\n",
      "\t dobj\n",
      "\t\t group\n",
      "-----------------------------\n",
      "spur\n",
      "\t nsubj\n",
      "\t\t state\n",
      "\t dobj\n",
      "\t\t possession\n",
      "-----------------------------\n",
      "compare\n",
      "\t nsubj\n",
      "\t\t Tops\n",
      "\t dobj\n",
      "\t\t state\n",
      "-----------------------------\n",
      "include\n",
      "\t dobj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "write\n",
      "\t dobj\n",
      "\t\t time\n",
      "-----------------------------\n",
      "believe\n",
      "\t nsubj\n",
      "\t\t quantity\n",
      "-----------------------------\n",
      "possess\n",
      "\t nsubj\n",
      "\t\t attribute\n",
      "\t dobj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "stress\n",
      "\t nsubj\n",
      "\t\t all\n",
      "\t dobj\n",
      "\t\t person\n",
      "-----------------------------\n",
      "compile\n",
      "\t dobj\n",
      "\t\t act\n",
      "-----------------------------\n",
      "describe\n",
      "\t dobj\n",
      "\t\t object\n",
      "-----------------------------\n",
      "reach\n",
      "\t dobj\n",
      "\t\t event\n",
      "-----------------------------\n",
      "allow\n",
      "\t dobj\n",
      "\t\t process\n",
      "-----------------------------\n",
      "present\n",
      "\t nsubj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "apply\n",
      "\t nsubj\n",
      "\t\t cognition\n",
      "\t dobj\n",
      "\t\t act\n",
      "-----------------------------\n",
      "delimit\n",
      "\t dobj\n",
      "\t\t attribute\n",
      "-----------------------------\n",
      "patent\n",
      "\t dobj\n",
      "\t\t act\n",
      "-----------------------------\n",
      "keep\n",
      "\t nsubj\n",
      "\t\t attribute\n",
      "-----------------------------\n",
      "plant\n",
      "\t nsubj\n",
      "\t\t act\n",
      "\t dobj\n",
      "\t\t artifact\n",
      "-----------------------------\n",
      "witness\n",
      "\t dobj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "image\n",
      "\t nsubj\n",
      "\t\t artifact\n",
      "\t dobj\n",
      "\t\t location\n",
      "-----------------------------\n",
      "spend\n",
      "\t nsubj\n",
      "\t\t competition\n",
      "-----------------------------\n",
      "illuminate\n",
      "\t nsubj\n",
      "\t\t communication\n",
      "\t dobj\n",
      "\t\t artifact\n",
      "-----------------------------\n",
      "hit\n",
      "\t dobj\n",
      "\t\t location\n",
      "-----------------------------\n",
      "choose\n",
      "\t nsubj\n",
      "\t\t communication\n",
      "\t dobj\n",
      "\t\t group\n",
      "-----------------------------\n",
      "influence\n",
      "\t dobj\n",
      "\t\t Tops\n",
      "-----------------------------\n",
      "feature\n",
      "\t nsubj\n",
      "\t\t communication\n",
      "\t dobj\n",
      "\t\t communication\n",
      "-----------------------------\n",
      "create\n",
      "\t nsubj\n",
      "\t\t act\n",
      "\t dobj\n",
      "\t\t cognition\n",
      "-----------------------------\n",
      "direct\n",
      "\t nsubj\n",
      "\t\t person\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "sm_slots = add_semantic_types(verbs)\n",
    "print_trees(sm_slots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
