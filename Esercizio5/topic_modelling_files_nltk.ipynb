{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m \u001b[39mimport\u001b[39;00m corpora\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m reuters\n\u001b[1;32m---> 11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyLDAvis\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk import MWETokenizer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def normalize(text):\n",
    "    text = re.sub(r'[^\\w\\s]',' ',text) # rimuovo la punteggiatura\n",
    "    text = text.lower()\n",
    "    text = nltk.pos_tag(text.split()) # prendo i pos tag delle parole (fa anche il tokenizing)\n",
    "    text = [x for x in text if x[1] in ['NN','NNS','NNP','NNPS']] # mantengo solo i noun\n",
    "    text = [x[0] for x in text] # rimuovo i pos tag\n",
    "    text = [lemmatizer.lemmatize(x) for x in text]\n",
    "    text = [x for x in text if x not in stop_words]\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il corpus Reuters è un popolare corpus linguistico utilizzato per la ricerca e l'elaborazione del linguaggio naturale. È composto da una vasta collezione di articoli di notizie provenienti dalla Reuters news agency, che copre una vasta gamma di argomenti come politica, economia, finanza, scienza, tecnologia e altro ancora. Il corpus Reuters è spesso utilizzato come benchmark per valutare algoritmi di classificazione del testo, modelli di linguaggio e altre applicazioni nel campo dell'elaborazione del linguaggio naturale. È incluso nella libreria NLTK (Natural Language Toolkit) di Python, che offre un facile accesso a numerosi corpus linguistici.\n",
    "\n",
    "Contiene 90 argomenti distinti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DOC_IDS = reuters.fileids()\n",
    "TOPICS = ['trade', 'grain', 'crude', 'acq', 'interest', 'money-fx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero documenti: 1354\n",
      "topics: ['trade', 'grain', 'crude', 'acq', 'interest', 'money-fx']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_topics(doc_ids):\n",
    "    topics = {}\n",
    "    for doc_id in doc_ids:\n",
    "        for topic in reuters.categories(doc_id):\n",
    "            if topic in topics:\n",
    "                topics[topic] += 1\n",
    "            else:\n",
    "                topics[topic] = 1\n",
    "\n",
    "    #order topics by frequency\n",
    "    topics = {k: v for k, v in sorted(topics.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    return topics\n",
    "\n",
    "def get_reuters_docs(test=True):\n",
    "    docs_ids = reuters.fileids()\n",
    "    if (test):\n",
    "        docs_ids = [doc_id for doc_id in ORIGINAL_DOC_IDS if 'test' in doc_id]\n",
    "        \n",
    "    i = 0\n",
    "    length = len(docs_ids)\n",
    "    while i < length:\n",
    "        #check if the document has exactly one topic in the list of topics\n",
    "        if len(set(reuters.categories(docs_ids[i])).intersection(set(TOPICS))) != 1:\n",
    "            docs_ids.remove(docs_ids[i])\n",
    "            length -= 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    docs = [normalize(reuters.raw(doc_id)) for doc_id in docs_ids]\n",
    "\n",
    "    return docs, docs_ids\n",
    "\n",
    "docs, docs_ids = get_reuters_docs()\n",
    "print('Numero documenti: ' + str(len(docs)))\n",
    "print('topics: ' + str(TOPICS))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I valori dell'output rappresentano i punteggi di coerenza associati ai rispettivi modelli LDA. \n",
    "Questi punteggi sono stati ottenuti mediante l'utilizzo del CoherenceModel. Esso calcola la coerenza \n",
    "dei topic utilizzando diverse metriche di coerenza, come ad esempio la metrica C_V. \n",
    "Queste metriche valutano la somiglianza semantica tra le parole chiave all'interno di ciascun topic, \n",
    "considerando anche la distribuzione delle parole nel corpus di testo.\n",
    "\"\"\"\n",
    "def fine_tuning(texts, limit, start=2, step=2):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    num_topic_list = []\n",
    "\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.3, keep_n=None)  # use Dictionary to remove un-relevant tokens\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "\n",
    "\n",
    "    for num_topics in range(start, limit, step):\n",
    "        print(\"Elaborazione per k = \" + str(num_topics))\n",
    "        model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        num_topic_list.append(num_topics)\n",
    "        coherencemodel = gensim.models.CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, num_topic_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elaborazione per k = 2\n",
      "Elaborazione per k = 4\n",
      "Elaborazione per k = 6\n",
      "Elaborazione per k = 8\n",
      "Elaborazione per k = 10\n"
     ]
    }
   ],
   "source": [
    "model_list, num_topic_list, coherence_values = fine_tuning(docs, 11, start=2, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 topic : 0.29005203919530526\n",
      "4 topic : 0.2908663009010457\n",
      "6 topic : 0.3564919904523756\n",
      "8 topic : 0.32680786476911294\n",
      "10 topic : 0.3054230422776756\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(num_topic_list)):\n",
    "    print(str(num_topic_list[i]) + \" topic : \" + str(coherence_values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello con 2 topic: \n",
      "\n",
      "Topic 0: 0.019*\"bank\" + 0.016*\"rate\" + 0.013*\"market\" + 0.012*\"trade\" + 0.012*\"year\" + 0.011*\"share\" + 0.011*\"oil\" + 0.010*\"group\" + 0.009*\"stock\" + 0.009*\"dollar\"\n",
      "Topic 1: 0.031*\"share\" + 0.016*\"oil\" + 0.015*\"price\" + 0.014*\"stock\" + 0.013*\"year\" + 0.012*\"offer\" + 0.009*\"market\" + 0.009*\"corp\" + 0.009*\"inc\" + 0.008*\"group\"\n",
      "\n",
      "\n",
      "Modello con 4 topic: \n",
      "\n",
      "Topic 0: 0.031*\"share\" + 0.016*\"rate\" + 0.015*\"year\" + 0.014*\"stock\" + 0.013*\"bank\" + 0.012*\"oil\" + 0.010*\"offer\" + 0.009*\"corp\" + 0.009*\"day\" + 0.008*\"group\"\n",
      "Topic 1: 0.020*\"price\" + 0.017*\"oil\" + 0.015*\"tonne\" + 0.015*\"rate\" + 0.013*\"corp\" + 0.011*\"year\" + 0.011*\"market\" + 0.009*\"share\" + 0.009*\"stock\" + 0.009*\"official\"\n",
      "Topic 2: 0.023*\"share\" + 0.016*\"stock\" + 0.014*\"market\" + 0.013*\"trade\" + 0.013*\"group\" + 0.013*\"inc\" + 0.012*\"tonne\" + 0.012*\"sale\" + 0.012*\"year\" + 0.010*\"offer\"\n",
      "Topic 3: 0.017*\"bank\" + 0.017*\"oil\" + 0.015*\"dollar\" + 0.014*\"market\" + 0.014*\"share\" + 0.012*\"price\" + 0.011*\"trade\" + 0.011*\"group\" + 0.010*\"year\" + 0.010*\"japan\"\n",
      "\n",
      "\n",
      "Modello con 6 topic: \n",
      "\n",
      "Topic 0: 0.018*\"market\" + 0.015*\"trade\" + 0.015*\"year\" + 0.015*\"dollar\" + 0.014*\"share\" + 0.013*\"oil\" + 0.011*\"group\" + 0.010*\"export\" + 0.009*\"price\" + 0.009*\"bank\"\n",
      "Topic 1: 0.057*\"share\" + 0.020*\"offer\" + 0.019*\"stock\" + 0.018*\"group\" + 0.016*\"stake\" + 0.013*\"corp\" + 0.012*\"inc\" + 0.011*\"year\" + 0.010*\"investment\" + 0.009*\"exchange\"\n",
      "Topic 2: 0.025*\"oil\" + 0.020*\"year\" + 0.017*\"day\" + 0.016*\"bank\" + 0.014*\"share\" + 0.012*\"price\" + 0.010*\"rate\" + 0.009*\"ct\" + 0.009*\"stock\" + 0.009*\"barrel\"\n",
      "Topic 3: 0.023*\"trade\" + 0.017*\"price\" + 0.017*\"market\" + 0.015*\"bank\" + 0.015*\"oil\" + 0.014*\"tonne\" + 0.008*\"rate\" + 0.008*\"year\" + 0.008*\"japan\" + 0.008*\"government\"\n",
      "Topic 4: 0.027*\"rate\" + 0.027*\"bank\" + 0.013*\"oil\" + 0.012*\"market\" + 0.011*\"share\" + 0.010*\"corp\" + 0.010*\"trade\" + 0.010*\"tonne\" + 0.010*\"week\" + 0.008*\"interest\"\n",
      "Topic 5: 0.016*\"stock\" + 0.015*\"oil\" + 0.014*\"rate\" + 0.014*\"year\" + 0.013*\"price\" + 0.013*\"share\" + 0.011*\"market\" + 0.010*\"agreement\" + 0.010*\"sale\" + 0.009*\"export\"\n",
      "\n",
      "\n",
      "Modello con 8 topic: \n",
      "\n",
      "Topic 0: 0.025*\"bank\" + 0.025*\"trade\" + 0.023*\"share\" + 0.017*\"group\" + 0.016*\"year\" + 0.014*\"market\" + 0.013*\"inc\" + 0.012*\"acquisition\" + 0.011*\"export\" + 0.010*\"exchange\"\n",
      "Topic 1: 0.036*\"share\" + 0.029*\"offer\" + 0.024*\"group\" + 0.021*\"stock\" + 0.014*\"market\" + 0.012*\"inc\" + 0.011*\"bid\" + 0.009*\"japan\" + 0.009*\"shareholder\" + 0.008*\"sale\"\n",
      "Topic 2: 0.029*\"tonne\" + 0.015*\"bank\" + 0.014*\"nil\" + 0.013*\"corp\" + 0.013*\"wheat\" + 0.013*\"month\" + 0.011*\"share\" + 0.011*\"year\" + 0.010*\"price\" + 0.010*\"agreement\"\n",
      "Topic 3: 0.039*\"oil\" + 0.025*\"price\" + 0.015*\"year\" + 0.014*\"barrel\" + 0.012*\"rate\" + 0.010*\"market\" + 0.010*\"production\" + 0.009*\"trade\" + 0.009*\"tonne\" + 0.009*\"export\"\n",
      "Topic 4: 0.037*\"share\" + 0.024*\"stock\" + 0.014*\"year\" + 0.012*\"oil\" + 0.011*\"corp\" + 0.010*\"offer\" + 0.009*\"inc\" + 0.008*\"bank\" + 0.008*\"rate\" + 0.008*\"tonne\"\n",
      "Topic 5: 0.030*\"rate\" + 0.018*\"market\" + 0.017*\"bank\" + 0.017*\"share\" + 0.016*\"dollar\" + 0.012*\"industry\" + 0.011*\"day\" + 0.011*\"group\" + 0.010*\"sale\" + 0.010*\"week\"\n",
      "Topic 6: 0.019*\"trade\" + 0.012*\"price\" + 0.012*\"agreement\" + 0.011*\"government\" + 0.011*\"share\" + 0.010*\"year\" + 0.010*\"week\" + 0.010*\"rate\" + 0.009*\"oil\" + 0.008*\"export\"\n",
      "Topic 7: 0.016*\"share\" + 0.013*\"rate\" + 0.011*\"year\" + 0.011*\"market\" + 0.011*\"corp\" + 0.011*\"dollar\" + 0.011*\"accord\" + 0.010*\"stock\" + 0.010*\"louvre\" + 0.009*\"interest\"\n",
      "\n",
      "\n",
      "Modello con 10 topic: \n",
      "\n",
      "Topic 0: 0.027*\"share\" + 0.021*\"rate\" + 0.017*\"offer\" + 0.015*\"stock\" + 0.014*\"inc\" + 0.014*\"bank\" + 0.012*\"interest\" + 0.012*\"price\" + 0.011*\"nil\" + 0.010*\"group\"\n",
      "Topic 1: 0.020*\"bank\" + 0.018*\"month\" + 0.016*\"gulf\" + 0.014*\"tonne\" + 0.011*\"oil\" + 0.010*\"rate\" + 0.009*\"wheat\" + 0.009*\"year\" + 0.009*\"market\" + 0.009*\"iran\"\n",
      "Topic 2: 0.025*\"bank\" + 0.015*\"share\" + 0.012*\"sale\" + 0.012*\"group\" + 0.012*\"agreement\" + 0.012*\"acquisition\" + 0.011*\"corp\" + 0.011*\"market\" + 0.011*\"price\" + 0.010*\"year\"\n",
      "Topic 3: 0.041*\"share\" + 0.019*\"oil\" + 0.018*\"dollar\" + 0.018*\"stock\" + 0.015*\"market\" + 0.014*\"bank\" + 0.011*\"offer\" + 0.011*\"inc\" + 0.009*\"rate\" + 0.008*\"year\"\n",
      "Topic 4: 0.022*\"rate\" + 0.020*\"price\" + 0.019*\"market\" + 0.018*\"group\" + 0.016*\"share\" + 0.015*\"bank\" + 0.009*\"oil\" + 0.009*\"japan\" + 0.009*\"day\" + 0.008*\"meeting\"\n",
      "Topic 5: 0.022*\"tonne\" + 0.020*\"year\" + 0.015*\"agreement\" + 0.015*\"share\" + 0.014*\"grain\" + 0.011*\"offer\" + 0.010*\"sale\" + 0.010*\"oil\" + 0.009*\"price\" + 0.009*\"business\"\n",
      "Topic 6: 0.037*\"share\" + 0.023*\"export\" + 0.019*\"year\" + 0.019*\"group\" + 0.016*\"stock\" + 0.014*\"oil\" + 0.011*\"month\" + 0.010*\"stake\" + 0.009*\"import\" + 0.009*\"price\"\n",
      "Topic 7: 0.035*\"oil\" + 0.015*\"barrel\" + 0.015*\"price\" + 0.014*\"corp\" + 0.014*\"year\" + 0.012*\"stock\" + 0.010*\"co\" + 0.010*\"sale\" + 0.009*\"ct\" + 0.009*\"surplus\"\n",
      "Topic 8: 0.026*\"trade\" + 0.019*\"rate\" + 0.018*\"year\" + 0.017*\"market\" + 0.014*\"price\" + 0.013*\"oil\" + 0.010*\"minister\" + 0.009*\"stock\" + 0.009*\"deficit\" + 0.008*\"export\"\n",
      "Topic 9: 0.027*\"tonne\" + 0.020*\"trade\" + 0.019*\"market\" + 0.012*\"corp\" + 0.012*\"inc\" + 0.011*\"share\" + 0.010*\"unit\" + 0.010*\"bank\" + 0.010*\"agreement\" + 0.009*\"sale\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(num_topic_list)):\n",
    "    print(f\"Modello con {num_topic_list[i]} topic: \\n\")\n",
    "    for topic_id, topic in model_list[i].show_topics(formatted=True, num_topics=num_topic_list[i], num_words=10):\n",
    "        print(f\"Topic {topic_id}: {topic}\")\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
