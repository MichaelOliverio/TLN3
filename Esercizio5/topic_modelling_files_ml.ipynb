{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 5 - Documenti BBC\n",
    "\n",
    "Si richiede un'implementazione di un esercizio di Topic Modeling, utilizzando librerie open (come ad es. GenSim (https://radimrehurek.com/gensim/). Si richiede l'utilizzo di un corpus di almeno 1k documenti. Testare un algoritmo (ad esempio LDA) con più valori di k (num. di topics) e valutare la coerenza dei risultati, attraverso fine-tuning su parametri e pre-processing. Update: essendo che spesso i topic, per essere interpretabili, devono contenere content words, potete pensare di filtrare solamente i sostantivi in fase di preprocessing (cioè POS=noun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk import MWETokenizer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing delle frasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = re.sub(r'[^\\w\\s]',' ',text) # rimuovo la punteggiatura\n",
    "    text = text.lower()\n",
    "    text = nltk.pos_tag(text.split()) # prendo i pos tag delle parole (fa anche il tokenizing)\n",
    "    text = [x for x in text if x[1] in ['NN','NNS','NNP','NNPS']] # mantengo solo i noun\n",
    "    text = [x[0] for x in text] # rimuovo i pos tag\n",
    "    text = [lemmatizer.lemmatize(x) for x in text]\n",
    "    text = [x for x in text if x not in stop_words]\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelevo i documenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents\\bbc\\entertainment contiene 128 files\n",
      "documents\\bbcsport\\athletics contiene 101 files\n",
      "documents\\bbcsport\\cricket contiene 124 files\n",
      "documents\\bbcsport\\football contiene 265 files\n",
      "documents\\bbcsport\\rugby contiene 147 files\n",
      "documents\\bbcsport\\tennis contiene 100 files\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"documents\\\\bbc\\\\entertainment\", \n",
    "    \"documents\\\\bbcsport\\\\athletics\", \n",
    "    \"documents\\\\bbcsport\\\\cricket\", \n",
    "    \"documents\\\\bbcsport\\\\football\", \n",
    "    \"documents\\\\bbcsport\\\\rugby\",\n",
    "    \"documents\\\\bbcsport\\\\tennis\"\n",
    "]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for path in paths:\n",
    "    print(path + ' contiene ' + str(len(os.listdir(path))) + ' files')\n",
    "    for file_name in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, file_name)):\n",
    "            file = open(path + \"/\" + file_name, \"r\", encoding=\"utf-8\")\n",
    "            document = preprocessing(file.read())\n",
    "            documents.append(document)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I valori dell'output rappresentano i punteggi di coerenza associati ai rispettivi modelli LDA. \n",
    "Questi punteggi sono stati ottenuti mediante l'utilizzo del CoherenceModel. Esso calcola la coerenza \n",
    "dei topic utilizzando diverse metriche di coerenza, come ad esempio la metrica C_V. \n",
    "Queste metriche valutano la somiglianza semantica tra le parole chiave all'interno di ciascun topic, \n",
    "considerando anche la distribuzione delle parole nel corpus di testo.\n",
    "\"\"\"\n",
    "def fine_tuning(texts, limit, start=2, step=1):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    num_topic_list = []\n",
    "\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.3, keep_n=None)  # use Dictionary to remove un-relevant tokens\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "\n",
    "\n",
    "    for num_topics in range(start, limit, step):\n",
    "        print(\"Elaborazione per il topic \" + str(num_topics))\n",
    "        model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        num_topic_list.append(num_topics)\n",
    "        coherencemodel = gensim.models.CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, num_topic_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elaborazione per il topic 2\n",
      "Elaborazione per il topic 3\n",
      "Elaborazione per il topic 4\n",
      "Elaborazione per il topic 5\n",
      "Elaborazione per il topic 6\n",
      "Elaborazione per il topic 7\n",
      "Elaborazione per il topic 8\n",
      "Elaborazione per il topic 9\n"
     ]
    }
   ],
   "source": [
    "model_list, num_topic_list, coherence_values = fine_tuning(documents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 topic : 0.3385441027087843\n",
      "3 topic : 0.35718001168050173\n",
      "4 topic : 0.39613896904985524\n",
      "5 topic : 0.33789973447331806\n",
      "6 topic : 0.34943276719709826\n",
      "7 topic : 0.3277788731532742\n",
      "8 topic : 0.3232278732396564\n",
      "9 topic : 0.3320317079282563\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(num_topic_list)):\n",
    "    print(str(num_topic_list[i]) + \" topic : \" + str(coherence_values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello con 2 topic: \n",
      "\n",
      "Topic 0: 0.010*\"england\" + 0.009*\"club\" + 0.008*\"cup\" + 0.007*\"test\" + 0.006*\"season\" + 0.006*\"injury\" + 0.006*\"chelsea\" + 0.005*\"ball\" + 0.005*\"minute\" + 0.005*\"series\"\n",
      "Topic 1: 0.007*\"film\" + 0.006*\"england\" + 0.006*\"wale\" + 0.005*\"champion\" + 0.005*\"goal\" + 0.005*\"coach\" + 0.005*\"ball\" + 0.005*\"test\" + 0.005*\"week\" + 0.005*\"point\"\n",
      "\n",
      "\n",
      "Modello con 3 topic: \n",
      "\n",
      "Topic 0: 0.009*\"club\" + 0.008*\"england\" + 0.007*\"chelsea\" + 0.007*\"champion\" + 0.007*\"cup\" + 0.007*\"season\" + 0.006*\"test\" + 0.006*\"injury\" + 0.005*\"number\" + 0.005*\"series\"\n",
      "Topic 1: 0.010*\"film\" + 0.008*\"goal\" + 0.007*\"club\" + 0.007*\"minute\" + 0.007*\"cup\" + 0.006*\"award\" + 0.006*\"england\" + 0.005*\"chance\" + 0.005*\"season\" + 0.005*\"half\"\n",
      "Topic 2: 0.011*\"england\" + 0.010*\"ball\" + 0.008*\"test\" + 0.006*\"coach\" + 0.006*\"week\" + 0.006*\"wale\" + 0.006*\"series\" + 0.006*\"half\" + 0.005*\"ireland\" + 0.005*\"nation\"\n",
      "\n",
      "\n",
      "Modello con 4 topic: \n",
      "\n",
      "Topic 0: 0.009*\"ball\" + 0.007*\"test\" + 0.006*\"season\" + 0.006*\"champion\" + 0.006*\"way\" + 0.006*\"club\" + 0.006*\"chelsea\" + 0.006*\"series\" + 0.006*\"number\" + 0.005*\"win\"\n",
      "Topic 1: 0.011*\"cup\" + 0.007*\"club\" + 0.007*\"point\" + 0.007*\"film\" + 0.007*\"manager\" + 0.006*\"champion\" + 0.006*\"half\" + 0.006*\"victory\" + 0.005*\"set\" + 0.005*\"home\"\n",
      "Topic 2: 0.010*\"film\" + 0.008*\"test\" + 0.008*\"goal\" + 0.007*\"minute\" + 0.006*\"england\" + 0.006*\"week\" + 0.005*\"ball\" + 0.005*\"champion\" + 0.005*\"win\" + 0.004*\"victory\"\n",
      "Topic 3: 0.016*\"england\" + 0.007*\"injury\" + 0.007*\"club\" + 0.007*\"coach\" + 0.007*\"rugby\" + 0.006*\"wale\" + 0.006*\"ireland\" + 0.006*\"nation\" + 0.006*\"season\" + 0.006*\"cup\"\n",
      "\n",
      "\n",
      "Modello con 5 topic: \n",
      "\n",
      "Topic 0: 0.010*\"club\" + 0.009*\"test\" + 0.009*\"england\" + 0.006*\"goal\" + 0.006*\"season\" + 0.006*\"cup\" + 0.005*\"liverpool\" + 0.005*\"injury\" + 0.005*\"home\" + 0.005*\"minute\"\n",
      "Topic 1: 0.018*\"england\" + 0.007*\"ball\" + 0.007*\"wale\" + 0.006*\"win\" + 0.006*\"series\" + 0.006*\"france\" + 0.005*\"jones\" + 0.005*\"test\" + 0.005*\"champion\" + 0.005*\"coach\"\n",
      "Topic 2: 0.010*\"film\" + 0.006*\"series\" + 0.006*\"victory\" + 0.006*\"way\" + 0.006*\"half\" + 0.005*\"home\" + 0.005*\"season\" + 0.005*\"minute\" + 0.005*\"injury\" + 0.005*\"rugby\"\n",
      "Topic 3: 0.009*\"film\" + 0.008*\"cup\" + 0.007*\"season\" + 0.007*\"club\" + 0.006*\"england\" + 0.006*\"award\" + 0.006*\"ball\" + 0.006*\"week\" + 0.005*\"decision\" + 0.005*\"goal\"\n",
      "Topic 4: 0.007*\"minute\" + 0.007*\"week\" + 0.006*\"england\" + 0.006*\"test\" + 0.006*\"goal\" + 0.006*\"cup\" + 0.005*\"injury\" + 0.005*\"club\" + 0.005*\"ball\" + 0.005*\"ireland\"\n",
      "\n",
      "\n",
      "Modello con 6 topic: \n",
      "\n",
      "Topic 0: 0.011*\"england\" + 0.007*\"cup\" + 0.007*\"coach\" + 0.007*\"chelsea\" + 0.007*\"test\" + 0.006*\"season\" + 0.006*\"way\" + 0.006*\"victory\" + 0.006*\"win\" + 0.005*\"lot\"\n",
      "Topic 1: 0.010*\"ball\" + 0.009*\"wale\" + 0.008*\"minute\" + 0.008*\"test\" + 0.008*\"cricket\" + 0.006*\"series\" + 0.006*\"england\" + 0.006*\"season\" + 0.005*\"home\" + 0.005*\"film\"\n",
      "Topic 2: 0.008*\"film\" + 0.007*\"champion\" + 0.006*\"record\" + 0.006*\"week\" + 0.006*\"goal\" + 0.006*\"test\" + 0.005*\"half\" + 0.005*\"club\" + 0.005*\"england\" + 0.005*\"injury\"\n",
      "Topic 3: 0.010*\"club\" + 0.009*\"england\" + 0.008*\"award\" + 0.007*\"film\" + 0.007*\"number\" + 0.006*\"way\" + 0.006*\"place\" + 0.006*\"minute\" + 0.005*\"test\" + 0.005*\"series\"\n",
      "Topic 4: 0.014*\"england\" + 0.009*\"cup\" + 0.008*\"test\" + 0.007*\"goal\" + 0.007*\"ball\" + 0.007*\"injury\" + 0.006*\"club\" + 0.006*\"minute\" + 0.005*\"win\" + 0.005*\"season\"\n",
      "Topic 5: 0.011*\"film\" + 0.011*\"club\" + 0.009*\"week\" + 0.008*\"v\" + 0.008*\"france\" + 0.007*\"rugby\" + 0.007*\"ireland\" + 0.007*\"number\" + 0.006*\"cup\" + 0.006*\"champion\"\n",
      "\n",
      "\n",
      "Modello con 7 topic: \n",
      "\n",
      "Topic 0: 0.011*\"goal\" + 0.010*\"ball\" + 0.007*\"club\" + 0.007*\"england\" + 0.007*\"test\" + 0.006*\"run\" + 0.006*\"win\" + 0.006*\"half\" + 0.006*\"minute\" + 0.005*\"cup\"\n",
      "Topic 1: 0.011*\"film\" + 0.009*\"england\" + 0.006*\"cup\" + 0.006*\"injury\" + 0.006*\"ball\" + 0.006*\"week\" + 0.005*\"chelsea\" + 0.005*\"number\" + 0.005*\"wale\" + 0.005*\"champion\"\n",
      "Topic 2: 0.011*\"season\" + 0.009*\"cup\" + 0.008*\"champion\" + 0.007*\"week\" + 0.007*\"club\" + 0.007*\"film\" + 0.006*\"series\" + 0.006*\"title\" + 0.006*\"injury\" + 0.005*\"break\"\n",
      "Topic 3: 0.018*\"england\" + 0.014*\"test\" + 0.007*\"season\" + 0.006*\"injury\" + 0.006*\"goal\" + 0.005*\"captain\" + 0.005*\"cup\" + 0.005*\"victory\" + 0.005*\"week\" + 0.005*\"ball\"\n",
      "Topic 4: 0.008*\"chelsea\" + 0.007*\"film\" + 0.007*\"club\" + 0.007*\"coach\" + 0.007*\"football\" + 0.006*\"test\" + 0.006*\"england\" + 0.006*\"point\" + 0.006*\"series\" + 0.005*\"ireland\"\n",
      "Topic 5: 0.007*\"chance\" + 0.007*\"cup\" + 0.007*\"france\" + 0.006*\"injury\" + 0.006*\"minute\" + 0.006*\"england\" + 0.006*\"goal\" + 0.005*\"home\" + 0.005*\"victory\" + 0.005*\"club\"\n",
      "Topic 6: 0.010*\"england\" + 0.009*\"club\" + 0.007*\"champion\" + 0.007*\"minute\" + 0.007*\"season\" + 0.006*\"test\" + 0.006*\"number\" + 0.006*\"woman\" + 0.005*\"bbc\" + 0.005*\"chelsea\"\n",
      "\n",
      "\n",
      "Modello con 8 topic: \n",
      "\n",
      "Topic 0: 0.012*\"england\" + 0.009*\"minute\" + 0.007*\"wale\" + 0.006*\"award\" + 0.006*\"goal\" + 0.006*\"chelsea\" + 0.006*\"ball\" + 0.005*\"chance\" + 0.005*\"jones\" + 0.005*\"season\"\n",
      "Topic 1: 0.011*\"england\" + 0.009*\"season\" + 0.009*\"champion\" + 0.009*\"club\" + 0.008*\"injury\" + 0.006*\"chance\" + 0.006*\"place\" + 0.005*\"minute\" + 0.005*\"cup\" + 0.005*\"johnson\"\n",
      "Topic 2: 0.008*\"test\" + 0.007*\"woman\" + 0.007*\"goal\" + 0.007*\"club\" + 0.007*\"film\" + 0.007*\"way\" + 0.006*\"home\" + 0.006*\"injury\" + 0.006*\"half\" + 0.005*\"week\"\n",
      "Topic 3: 0.014*\"film\" + 0.008*\"england\" + 0.007*\"france\" + 0.007*\"ball\" + 0.007*\"club\" + 0.007*\"season\" + 0.006*\"minute\" + 0.006*\"coach\" + 0.005*\"week\" + 0.005*\"champion\"\n",
      "Topic 4: 0.009*\"england\" + 0.008*\"ball\" + 0.007*\"test\" + 0.007*\"series\" + 0.007*\"cup\" + 0.007*\"coach\" + 0.007*\"ireland\" + 0.006*\"goal\" + 0.005*\"nation\" + 0.005*\"point\"\n",
      "Topic 5: 0.011*\"cup\" + 0.010*\"england\" + 0.007*\"test\" + 0.007*\"chelsea\" + 0.006*\"cricket\" + 0.006*\"ball\" + 0.006*\"jones\" + 0.006*\"victory\" + 0.005*\"week\" + 0.005*\"fan\"\n",
      "Topic 6: 0.012*\"film\" + 0.011*\"number\" + 0.007*\"club\" + 0.006*\"england\" + 0.006*\"week\" + 0.006*\"chelsea\" + 0.005*\"half\" + 0.005*\"star\" + 0.005*\"squad\" + 0.005*\"season\"\n",
      "Topic 7: 0.012*\"test\" + 0.008*\"cup\" + 0.006*\"series\" + 0.006*\"number\" + 0.006*\"home\" + 0.006*\"injury\" + 0.006*\"chelsea\" + 0.006*\"v\" + 0.006*\"club\" + 0.005*\"film\"\n",
      "\n",
      "\n",
      "Modello con 9 topic: \n",
      "\n",
      "Topic 0: 0.009*\"film\" + 0.008*\"award\" + 0.008*\"club\" + 0.006*\"week\" + 0.006*\"ball\" + 0.006*\"manager\" + 0.005*\"champion\" + 0.005*\"season\" + 0.005*\"half\" + 0.005*\"jones\"\n",
      "Topic 1: 0.017*\"film\" + 0.009*\"champion\" + 0.007*\"england\" + 0.006*\"club\" + 0.006*\"season\" + 0.005*\"win\" + 0.005*\"ball\" + 0.005*\"series\" + 0.005*\"month\" + 0.005*\"test\"\n",
      "Topic 2: 0.011*\"club\" + 0.008*\"goal\" + 0.008*\"minute\" + 0.007*\"england\" + 0.006*\"film\" + 0.006*\"week\" + 0.006*\"manager\" + 0.006*\"football\" + 0.006*\"season\" + 0.006*\"series\"\n",
      "Topic 3: 0.012*\"chelsea\" + 0.010*\"minute\" + 0.009*\"goal\" + 0.009*\"number\" + 0.008*\"ball\" + 0.007*\"point\" + 0.006*\"drug\" + 0.006*\"chance\" + 0.005*\"club\" + 0.005*\"test\"\n",
      "Topic 4: 0.013*\"england\" + 0.008*\"coach\" + 0.008*\"victory\" + 0.007*\"win\" + 0.007*\"minute\" + 0.007*\"jones\" + 0.006*\"season\" + 0.005*\"test\" + 0.005*\"try\" + 0.005*\"wale\"\n",
      "Topic 5: 0.009*\"ball\" + 0.009*\"cup\" + 0.008*\"england\" + 0.006*\"minute\" + 0.006*\"test\" + 0.006*\"injury\" + 0.006*\"cricket\" + 0.006*\"goal\" + 0.005*\"france\" + 0.005*\"way\"\n",
      "Topic 6: 0.013*\"england\" + 0.008*\"cup\" + 0.008*\"injury\" + 0.006*\"goal\" + 0.006*\"week\" + 0.006*\"chance\" + 0.006*\"ireland\" + 0.006*\"wale\" + 0.005*\"season\" + 0.005*\"coach\"\n",
      "Topic 7: 0.011*\"test\" + 0.009*\"england\" + 0.007*\"series\" + 0.007*\"roddick\" + 0.007*\"coach\" + 0.006*\"point\" + 0.006*\"season\" + 0.006*\"way\" + 0.006*\"cup\" + 0.006*\"decision\"\n",
      "Topic 8: 0.012*\"club\" + 0.009*\"rugby\" + 0.009*\"test\" + 0.009*\"cup\" + 0.007*\"england\" + 0.006*\"wale\" + 0.006*\"football\" + 0.006*\"home\" + 0.006*\"month\" + 0.005*\"ball\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(num_topic_list)):\n",
    "    print(f\"Modello con {num_topic_list[i]} topic: \\n\")\n",
    "    for topic_id, topic in model_list[i].show_topics(formatted=True, num_topics=num_topic_list[i], num_words=10):\n",
    "        print(f\"Topic {topic_id}: {topic}\")\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
