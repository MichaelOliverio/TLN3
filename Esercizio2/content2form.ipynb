{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione 2\n",
    "\n",
    "Sempre partendo dai dati sulle definizioni, si richiede di provare a costruire un sistema che utilizzi la molteplicità delle definizioni per risalire al termine \"target\" in maniera automatica. Non si richiede di \"indovinare\" ogni termine, ma di avvicinarsi (almeno semanticamente) alla risposta. Provare più soluzioni, includendo meccanismi di filtro delle definizioni (ad es. escludendo quelle meno informative o con caratteristiche particolari), di ricerca nell'albero tassonomico di WordNet (provando a partire da candidati \"genus\", secondo il principio Genus-Differentia), ecc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clear_sentence(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation] #tolgo la punteggiatura\n",
    "    tokens = [token.lower() for token in tokens] # sostituisco le maiuscole con le minuscole\n",
    "    tokens = [token for token in tokens if token not in stop_words] # rimuovo le stop words\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens] # lemmatizzo\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodi di supporto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dato un token ritorna una lista di iponimi\n",
    "\"\"\"\n",
    "def get_hypoyms(token):\n",
    "    synonyms = wn.synsets(token)\n",
    "\n",
    "    hyponyms = []\n",
    "    for syn in synonyms:\n",
    "        hyponyms += syn.hyponyms()\n",
    "\n",
    "    hyponyms = [syn.lemmas()[0].name() for syn in hyponyms]\n",
    "\n",
    "    return hyponyms\n",
    "\n",
    "\"\"\"\n",
    "Dato un token ritorna una lista di iperonimi\n",
    "\"\"\"\n",
    "def get_hypernyms(token):\n",
    "    synonyms = wn.synsets(token)\n",
    "\n",
    "    hypernyms = []\n",
    "    for syn in synonyms:\n",
    "        hypernyms += syn.hypernyms()\n",
    "\n",
    "    hypernyms = [syn.lemmas()[0].name() for syn in hypernyms]\n",
    "\n",
    "    return hypernyms\n",
    "\n",
    "def get_context(definitions):\n",
    "    context = set()\n",
    "    for definition in definitions:\n",
    "        context = context.union(set(definition))\n",
    "    return context\n",
    "\n",
    "def simplified_lesk(word, context):\n",
    "    best_sense = None\n",
    "    max_overlap = 0\n",
    "\n",
    "    for sense in wn.synsets(word, pos='n'):\n",
    "        signature = set(clear_sentence(sense.definition())).union(set(clear_sentence(' '.join(sense.examples()))))\n",
    "        overlap = len(context.intersection(signature))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "    \n",
    "    return best_sense\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ottenimento del geneus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Restituisce come geneus il token che compare più volte nelle definizioni\n",
    "'''\n",
    "def get_geneus(definitions, syn = None):\n",
    "    words = []\n",
    "    for definition in definitions:\n",
    "        words += definition\n",
    "\n",
    "    # se ho il synset aggiungo alle parole anche la definizione del synset\n",
    "    if syn is not None:\n",
    "        words += clear_sentence(syn.definition())\n",
    "\n",
    "    return nltk.FreqDist(words).most_common(1)[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approccio 1: recursive simplified lesk\n",
    "\n",
    "Partendo dal geneus, si prendono tutti i suoi synset, e ad ognuno di essi si applica il recursive_simplified_lesk. La caratteristica\n",
    "di questo algoritmo è che non si ferma al primo livello di iponimi del geneus, ma per ognuno di essi scende di un certo numero di livelli (iperparametro da specificare). Così facendo vengono analizzati un numero maggiore di synsets così da avere più probabilità di ottenere il synset corretto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Variante ricorsiva del lesk, che permette di scendere di livello nella\n",
    "gerarchia del geneus\n",
    "'''\n",
    "def recursive_simplified_lesk(level, best_sense, current_syn, max_overlap, context):\n",
    "    if level == 0:\n",
    "        return [best_sense, max_overlap]\n",
    "    else:\n",
    "        for syn in current_syn.hyponyms():\n",
    "            signature = set(clear_sentence(syn.definition())).union(clear_sentence(' ' .join(syn.examples())))\n",
    "            overlap = len(context.intersection(signature))\n",
    "            if overlap >= max_overlap:\n",
    "                max_overlap = overlap\n",
    "                best_sense = syn\n",
    "\n",
    "        return recursive_simplified_lesk(level - 1, best_sense, current_syn, max_overlap, context)\n",
    "\n",
    "'''\n",
    "Metodo per predire il token dato un insieme di definizioni\n",
    "'''\n",
    "def predict_token(definitions, geneus):\n",
    "    best_sense = None\n",
    "    max_overlap = 0\n",
    "\n",
    "    # ottengo il contesto\n",
    "    context = get_context(definitions)\n",
    "\n",
    "    # per ogni synset del geneus cerco il synset con il massimo overlap \n",
    "    # con il contesto, andando ad usare una variante personalizzata\n",
    "    # del simplified lesk\n",
    "    for syn_geneus in wn.synsets(geneus):    \n",
    "        sense, overlap = recursive_simplified_lesk(3, best_sense, syn_geneus, max_overlap, context)\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "\n",
    "    return best_sense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approccio 2: rimozione definizioni poco informative + recursive simplified lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_uninformative_definitions(definitions, syn):\n",
    "    syn_definition = clear_sentence(syn.definition())\n",
    "\n",
    "    defs_overlap = []\n",
    "    # per ogni definizione calcolo l'overlap con la definizione del synset\n",
    "    for definition in definitions:\n",
    "        defs_overlap.append(len(set(definition).intersection(set(syn_definition))))\n",
    "\n",
    "    # rimuovo le definizioni che hanno overlap minore\n",
    "    min_overlap = min(defs_overlap)\n",
    "    \n",
    "    new_definitions = []\n",
    "    for i in range(len(definitions)):\n",
    "        if defs_overlap[i] != min_overlap:\n",
    "            new_definitions.append(definitions[i])\n",
    "\n",
    "    return new_definitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>door</th>\n",
       "      <th>ladybug</th>\n",
       "      <th>pain</th>\n",
       "      <th>blurriness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A construction used to divide two rooms, tempo...</td>\n",
       "      <td>small flying insect, typically red with black ...</td>\n",
       "      <td>A feeling of physical or mental distress</td>\n",
       "      <td>sight out of focus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's an opening, it can be opened or closed.</td>\n",
       "      <td>It is an insect, it has wings, red with black ...</td>\n",
       "      <td>It is a feeling, physical or emotional. It is ...</td>\n",
       "      <td>It is the absence of definite borders, shapele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An object that divide two room, closing an hol...</td>\n",
       "      <td>An insect that can fly. It has red or orange c...</td>\n",
       "      <td>A felling that couscious beings can experince ...</td>\n",
       "      <td>A sensation felt when you can't see clearly th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Usable for access from one area to another</td>\n",
       "      <td>Small insect with a red back</td>\n",
       "      <td>Concept that describes a suffering living being</td>\n",
       "      <td>Lack of sharpness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Structure that delimits an area and allows acc...</td>\n",
       "      <td>Small round flying insect</td>\n",
       "      <td>Feeling of physical discomfort</td>\n",
       "      <td>Characteristic of lack of clarity or precision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                door  \\\n",
       "0  A construction used to divide two rooms, tempo...   \n",
       "1       It's an opening, it can be opened or closed.   \n",
       "2  An object that divide two room, closing an hol...   \n",
       "3         Usable for access from one area to another   \n",
       "4  Structure that delimits an area and allows acc...   \n",
       "\n",
       "                                             ladybug  \\\n",
       "0  small flying insect, typically red with black ...   \n",
       "1  It is an insect, it has wings, red with black ...   \n",
       "2  An insect that can fly. It has red or orange c...   \n",
       "3                       Small insect with a red back   \n",
       "4                          Small round flying insect   \n",
       "\n",
       "                                                pain  \\\n",
       "0           A feeling of physical or mental distress   \n",
       "1  It is a feeling, physical or emotional. It is ...   \n",
       "2  A felling that couscious beings can experince ...   \n",
       "3    Concept that describes a suffering living being   \n",
       "4                     Feeling of physical discomfort   \n",
       "\n",
       "                                          blurriness  \n",
       "0                                 sight out of focus  \n",
       "1  It is the absence of definite borders, shapele...  \n",
       "2  A sensation felt when you can't see clearly th...  \n",
       "3                                  Lack of sharpness  \n",
       "4     Characteristic of lack of clarity or precision  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('definizioni.tsv', sep='\\t', engine='python')\n",
    "corpus.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['door'] = corpus['door'].apply(clear_sentence)\n",
    "corpus['ladybug'] = corpus['ladybug'].apply(clear_sentence)\n",
    "corpus['pain'] = corpus['pain'].apply(clear_sentence)\n",
    "corpus['blurriness'] = corpus['blurriness'].apply(clear_sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicazione approccio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: door\n",
      "geneus: room\n",
      "predicted token: study.n.05\n",
      "\n",
      "\n",
      "token: ladybug\n",
      "geneus: insect\n",
      "predicted token: dipterous_insect.n.01\n",
      "\n",
      "\n",
      "token: pain\n",
      "geneus: feeling\n",
      "predicted token: affection.n.01\n",
      "\n",
      "\n",
      "token: blurriness\n",
      "geneus: see\n",
      "predicted token: take.v.06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in corpus.columns:\n",
    "    geneus = get_geneus(corpus[token])\n",
    "    predicted_token = predict_token(corpus[token], geneus)\n",
    "\n",
    "    print('token: ' + token)\n",
    "    print(\"geneus: \" + geneus)\n",
    "    print(\"predicted token: \" + predicted_token.name())\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicazione approccio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in ['door', 'ladybug', 'pain', 'blurriness']:\n",
    "    syn = simplified_lesk(token, get_context(corpus[token]))\n",
    "    \n",
    "    #sostituisce il contenuto di corpus_copy[token] con le definizioni senza quelle che hanno overlap minore\n",
    "    new_definitions = remove_uninformative_definitions(corpus[token], syn)\n",
    "    geneus = get_geneus(new_definitions, syn)\n",
    "    predicted_token = predict_token(corpus[token], geneus)\n",
    "\n",
    "    print('Token: ', token)\n",
    "    print('Geneus: ', geneus)\n",
    "    print(\"predicted token: \" + predicted_token.name())\n",
    "    print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
